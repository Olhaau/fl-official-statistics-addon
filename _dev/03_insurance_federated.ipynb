{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Olhaau/fl-official-statistics-addon/blob/main/_dev/03_insurance_federated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1N2mtyx2Uxs"
   },
   "source": [
    "# Medical Insurance - a Federated Learning Use Case.\n",
    "\n",
    "This notebook contains Federated Learning.\n",
    "\n",
    "-- **more tba** --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qdJnO4M7VDO"
   },
   "source": [
    "## Setup\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZQgDGzbd3pm"
   },
   "source": [
    "### Pull Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-03-28T11:35:39.951921Z",
     "iopub.status.busy": "2023-03-28T11:35:39.950864Z",
     "iopub.status.idle": "2023-03-28T11:36:02.975338Z",
     "shell.execute_reply": "2023-03-28T11:36:02.974338Z",
     "shell.execute_reply.started": "2023-03-28T11:35:39.951921Z"
    },
    "id": "F5qBP638d0iR",
    "outputId": "8066ebff-16a5-4d22-9359-3097894f4cc2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "C:\\Users\\olisc\\OneDrive\\code\\py\\fl\\fl-official-statistics-addon\\_dev\\fl-official-statistics-addon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'fl-official-statistics-addon'...\n",
      "error: unable to create file original_work/pm-bejing/models/federated_cross_val/fed_cross_val-6-4-arch-K0-reduce-ev64-b-192-lstm-SGD0.1-SGD1-9-features/variables/variables.data-00000-of-00001: Filename too long\n",
      "error: unable to create file original_work/pm-bejing/models/federated_cross_val/fed_cross_val-6-4-arch-K1-reduce-ev64-b-192-lstm-SGD0.1-SGD1-9-features/variables/variables.data-00000-of-00001: Filename too long\n",
      "error: unable to create file original_work/pm-bejing/models/federated_cross_val/fed_cross_val-6-4-arch-K2-reduce-ev64-b-192-lstm-SGD0.1-SGD1-9-features/variables/variables.data-00000-of-00001: Filename too long\n",
      "error: unable to create file original_work/pm-bejing/models/federated_cross_val/fed_cross_val-6-4-arch-K3-reduce-ev64-b-192-lstm-SGD0.1-SGD1-9-features/variables/variables.data-00000-of-00001: Filename too long\n",
      "error: unable to create file original_work/pm-bejing/models/federated_cross_val/fed_cross_val-6-4-arch-K4-reduce-ev64-b-192-lstm-SGD0.1-SGD1-9-features/variables/variables.data-00000-of-00001: Filename too long\n",
      "fatal: unable to checkout working tree\n",
      "warning: Clone succeeded, but checkout failed.\n",
      "You can inspect what was checked out with 'git status'\n",
      "and retry with 'git restore --source=HEAD :/'\n",
      "\n",
      "From https://github.com/Olhaau/fl-official-statistics-addon\n",
      " * [new branch]      main       -> origin/main\n",
      "There is no tracking information for the current branch.\n",
      "Please specify which branch you want to merge with.\n",
      "See git-pull(1) for details.\n",
      "\n",
      "    git pull <remote> <branch>\n",
      "\n",
      "If you wish to set tracking information for this branch you can do so with:\n",
      "\n",
      "    git branch --set-upstream-to=origin/<branch> master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# rm repo from gdrive\n",
    "if os.path.exists(\"fl-official-statistics-addon\"):\n",
    "  %rm -r fl-official-statistics-addon\n",
    "\n",
    "# clone\n",
    "!git clone https://github.com/Olhaau/fl-official-statistics-addon\n",
    "%cd fl-official-statistics-addon\n",
    "\n",
    "# pull (the currenct version of the repo)\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1d5TMrK67Xxv"
   },
   "source": [
    "### Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UQSYlSd47WaM"
   },
   "outputs": [],
   "source": [
    "  !pip install --quiet nest_asyncio\n",
    "  !pip install --quiet tensorflow_federated\n",
    "  !pip install --quiet tensorflow_addons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUcRlUPV7bZi"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2zMmbNFf7Wc6"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "from tensorflow_addons.metrics import RSquare\n",
    "import tensorflow_addons as tfa\n",
    "import nest_asyncio\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxFNFscq8O74"
   },
   "source": [
    "## Ingest and Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "C9zyHqiN9fCo",
    "outputId": "9fbc2b08-2124-47b7-d322-af1b74aedd56"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ae933620-7f36-4212-a44d-a1a3c56c644c\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "      <th>region0</th>\n",
       "      <th>region1</th>\n",
       "      <th>region2</th>\n",
       "      <th>region3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.479150</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.217391</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.458434</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.326087</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.304348</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.347592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae933620-7f36-4212-a44d-a1a3c56c644c')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-ae933620-7f36-4212-a44d-a1a3c56c644c button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-ae933620-7f36-4212-a44d-a1a3c56c644c');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "        age  sex       bmi  children  smoker     region      charges  region0  \\\n",
       "0  0.021739  0.0  0.321227       0.0     1.0  southwest  16884.92400      0.0   \n",
       "1  0.000000  1.0  0.479150       0.2     0.0  southeast   1725.55230      0.0   \n",
       "2  0.217391  1.0  0.458434       0.6     0.0  southeast   4449.46200      0.0   \n",
       "3  0.326087  1.0  0.181464       0.0     0.0  northwest  21984.47061      0.0   \n",
       "4  0.304348  1.0  0.347592       0.0     0.0  northwest   3866.85520      0.0   \n",
       "\n",
       "   region1  region2  region3  \n",
       "0      0.0      0.0      1.0  \n",
       "1      0.0      1.0      0.0  \n",
       "2      0.0      1.0      0.0  \n",
       "3      1.0      0.0      0.0  \n",
       "4      1.0      0.0      0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"output/data/insurance-clean.csv\", index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Qam6babo7Wgg"
   },
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 4\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 10\n",
    "SHUFFLE_BUFFER = 20\n",
    "PREFETCH_BUFFER = 5\n",
    "NUM_ROUNDS = 150\n",
    "RUN_NAME = f'0,8-3({NUM_ROUNDS})-{NUM_EPOCHS}-epochs-{BATCH_SIZE}-batch-WithRegion/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JTutbOjq8VzQ"
   },
   "outputs": [],
   "source": [
    "syn_samples_per_region = 1000\n",
    "\n",
    "def get_dataset_for_region(dataset, region_index, test_size_per_region=20):\n",
    "    \"\"\"Min-max scale and return data for a single, given region. The scaler must be fitted before.\n",
    "\n",
    "    :param dataset: The dataset to get the regional data from\n",
    "    :type dataset: pandas.DataFrame\n",
    "    :param region_index: The index number of the region to return\n",
    "    :type region_index: int\n",
    "    :param test_size_per_region: The amount of values to separate for testing, default are 20\n",
    "    :type test_size_per_region: int, optional\n",
    "    :return: The dataset specific for the defined region, the test values, the test labels\n",
    "    :rtype: tensorflow.python.data.ops.dataset_ops.PrefetchDataset, tuple of pandas.core.series.Series\n",
    "    \"\"\"\n",
    "    region_ds = dataset[dataset['region'] == region_index]\n",
    "    region_ds = region_ds.drop(columns=['region'])\n",
    "    len = region_ds.shape[0]\n",
    "\n",
    "    # The scaling into [0, 1] is not necessary anymore, it happens when the data loads already\n",
    "    # region_ds[['age', 'bmi', 'children']] = scaler.transform(region_ds[['age', 'bmi', 'children']])\n",
    "\n",
    "    X_test = region_ds.head(test_size_per_region)\n",
    "    y_test = X_test.pop('charges')\n",
    "\n",
    "    X_train = region_ds.tail(len - test_size_per_region)\n",
    "    y_train = X_train.pop('charges')\n",
    "\n",
    "    fed_train_dataset = tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(X_train), tf.convert_to_tensor(y_train)))\n",
    "\n",
    "    return (\n",
    "        fed_train_dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER, seed=1).batch(BATCH_SIZE).prefetch(PREFETCH_BUFFER),\n",
    "        (X_test, y_test)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8FEwLlGv8eq3"
   },
   "outputs": [],
   "source": [
    "# Create test and train sets and put them into random_client_ds, use four clients which are independent of the region\n",
    "def get_dataset_random_region(dataset, num_clients=4, test_size_per_region=20):\n",
    "    \"\"\"Creates a list with client datasets independent of the region.\n",
    "\n",
    "    :param dataset: The dataset to get the regional data from\n",
    "    :type dataset: pandas.DataFrame\n",
    "    :param num_clients: the number of clients create (equal big datasets per client), default value is 4 clients\n",
    "    :type num_clients: int, optional\n",
    "    :param test_size_per_region: The amount of values to separate for testing, default are 20\n",
    "    :type test_size_per_region: int, optional\n",
    "    :return: List of the prepared dataset with one entry per region, the test values and labels for each region\n",
    "    :rtype: List of (tensorflow.python.data.ops.dataset_ops.PrefetchDataset, tuple of pandas.core.series.Series)\"\"\"\n",
    "    size_of_client_ds = int(dataset.shape[0] / num_clients)\n",
    "\n",
    "    dataset_to_split = dataset.copy()\n",
    "    dataset_to_split.pop(\"region\")\n",
    "    random_client_ds = []\n",
    "    for i in range(num_clients):\n",
    "        sampled = dataset_to_split.sample(n=size_of_client_ds)\n",
    "        dataset_to_split.drop(sampled.index)\n",
    "\n",
    "        X_test = sampled.head(test_size_per_region)\n",
    "        y_test = X_test.pop('charges')\n",
    "\n",
    "        X_train = sampled.tail(size_of_client_ds - test_size_per_region)\n",
    "        y_train = X_train.pop('charges')\n",
    "\n",
    "        fed_train_dataset = tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(X_train), tf.convert_to_tensor(y_train)))\n",
    "\n",
    "        train_set = fed_train_dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER, seed=1).batch(BATCH_SIZE).prefetch(PREFETCH_BUFFER)\n",
    "        test_set = (X_test, y_test)\n",
    "\n",
    "        random_client_ds.append((train_set, test_set))\n",
    "\n",
    "    return random_client_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dirvrz6Y9ARK",
    "outputId": "ac9d544c-2b97-42f1-c30d-c7cb60f4e8c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<PrefetchDataset element_spec=(TensorSpec(shape=(None, 5), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>,\n",
       "  (Empty DataFrame\n",
       "   Columns: [age, sex, bmi, children, smoker]\n",
       "   Index: [], Series([], Name: charges, dtype: float64))),\n",
       " (<PrefetchDataset element_spec=(TensorSpec(shape=(None, 5), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>,\n",
       "  (Empty DataFrame\n",
       "   Columns: [age, sex, bmi, children, smoker]\n",
       "   Index: [], Series([], Name: charges, dtype: float64))),\n",
       " (<PrefetchDataset element_spec=(TensorSpec(shape=(None, 5), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>,\n",
       "  (Empty DataFrame\n",
       "   Columns: [age, sex, bmi, children, smoker]\n",
       "   Index: [], Series([], Name: charges, dtype: float64)))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data for clients with regional data (each client one region)\n",
    "test_size_per_region = 20\n",
    "regions = ['region0', 'region1', 'region2', 'region3']\n",
    "\n",
    "federated_insurance_data = [\n",
    "    get_dataset_for_region(df.drop(regions, axis=1), i, test_size_per_region=test_size_per_region)\n",
    "    for i in range(NUM_CLIENTS-1)]\n",
    "federated_insurance_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "mX6HRriR9Cil"
   },
   "outputs": [],
   "source": [
    "# Training data for clients with regional independent data\n",
    "random_client_ds = get_dataset_random_region(df, num_clients=NUM_CLIENTS, test_size_per_region=test_size_per_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiNQ6m66A7sa"
   },
   "source": [
    "### Code Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VRbSvR-Q9058",
    "outputId": "481b1bf9-0b9c-4a75-8482-dc0525bc16c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitted datasets: 3\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"splitted datasets: {}\".format(len(federated_insurance_data)))\n",
    "print(\"------------------------------\")\n",
    "# Q: why range(NUM_CLIENTS-1) and, thus, only 3 clients?\n",
    "\n",
    "# Q: how to output? -> does not work or nothing in it?\n",
    "# -> i think its empty\n",
    "list(federated_insurance_data[0][0].as_numpy_iterator())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJY8_tVdCXrz"
   },
   "source": [
    "#### Show Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nFohPc1rAqVw",
    "outputId": "0ef2d47c-789e-4a40-b973-257b481bd722"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=(TensorSpec(shape=(4,), dtype=tf.float64, name=None), TensorSpec(shape=(), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Tensor Object\n",
    "X_train = df.iloc[:,0:4]\n",
    "y_train = df['charges']\n",
    "df2 = tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(X_train), tf.convert_to_tensor(y_train)))\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NpW57hM4DOBI",
    "outputId": "52db0c83-c7f8-4430-d372-1059ccdd9ed5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([0.02173913, 0.        , 0.3212268 , 0.        ]), 16884.924),\n",
       " (array([0.        , 1.        , 0.47914985, 0.2       ]), 1725.5523),\n",
       " (array([0.2173913 , 1.        , 0.45843422, 0.6       ]), 4449.462),\n",
       " (array([0.32608696, 1.        , 0.18146355, 0.        ]), 21984.47061),\n",
       " (array([0.30434783, 1.        , 0.34759214, 0.        ]), 3866.8552),\n",
       " (array([0.2826087 , 0.        , 0.26311542, 0.        ]), 3756.6216),\n",
       " (array([0.60869565, 0.        , 0.47027172, 0.2       ]), 8240.5896),\n",
       " (array([0.41304348, 0.        , 0.31692225, 0.6       ]), 7281.5056),\n",
       " (array([0.41304348, 1.        , 0.37315039, 0.4       ]), 6406.4107),\n",
       " (array([0.91304348, 0.        , 0.26580576, 0.        ]), 28923.13692)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show Tensor Object\n",
    "# S. https://stackoverflow.com/questions/62436302/extract-target-from-tensorflow-prefetchdataset\n",
    "list(df2.as_numpy_iterator())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "fx5SFZNkDptQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PvPyDQL8iXm"
   },
   "source": [
    "## Model Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "9Csom8dD8hRK"
   },
   "outputs": [],
   "source": [
    "def create_keras_model(\n",
    "    input_features = 9,\n",
    "    initializer = 'zeros',\n",
    "    units = [16,6,1],\n",
    "    activation = None\n",
    "    ):\n",
    "    \"\"\"Create neural network for given number of input features)\n",
    "\n",
    "    :param input_features: The dimension of the first layer with represents the amount of features used\n",
    "    :type input_features: int, optional\n",
    "    :return: Created but not compiled model\n",
    "    :rtype: keras.Model\n",
    "    \"\"\"\n",
    "    return tf.keras.models.Sequential([\n",
    "        # without region: tf.keras.layers.InputLayer(input_shape=(5,)),\n",
    "        tf.keras.layers.InputLayer(input_shape=(input_features,)),\n",
    "        tf.keras.layers.Dense(units[0], kernel_initializer=initializer, activation = activation\n",
    "                              ),\n",
    "        tf.keras.layers.Dense(units[1], kernel_initializer=initializer, activation = activation\n",
    "                              ),\n",
    "        tf.keras.layers.Dense(units[2], kernel_initializer=initializer)\n",
    "    ])\n",
    "\n",
    "\n",
    "# A helper function for federated learning\n",
    "def model_fn(    \n",
    "    input_features = 9,\n",
    "    initializer = 'zeros',\n",
    "    units = [16,6,1],\n",
    "    activation = None):\n",
    "    \"\"\"A function for TFF to create a local model during federated learning and return it as the correct type.\n",
    "    This model uses 9 input features i.e. the regions are part of the features.\n",
    "\n",
    "    :return: The LSTM model to be used as federated models\n",
    "    :rtype: tff.learning.Model\n",
    "    \"\"\"\n",
    "    # We _must_ create a new model here, and _not_ capture it from an external\n",
    "    # scope. TFF will call this within different graph contexts.\n",
    "    keras_model = create_keras_model(\n",
    "            input_features = input_features,\n",
    "            initializer = initializer,\n",
    "            activation = activation,\n",
    "            units = units\n",
    "    )\n",
    "    return tff.learning.from_keras_model(\n",
    "        keras_model,\n",
    "        # without region: \n",
    "        #input_spec = federated_insurance_data[0][0].element_spec,\n",
    "        input_spec = random_client_ds[0][0].element_spec,\n",
    "        loss = tf.keras.losses.MeanAbsoluteError(),\n",
    "        metrics = [tf.keras.metrics.MeanAbsoluteError()\n",
    "        #,tfa.metrics.RSquare()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Helper functions for different features as input\n",
    "def model_fn_5():\n",
    "    return model_fn(5)\n",
    "\n",
    "def model_fn_5_mod():\n",
    "  return model_fn(5, initializer = 'glorot_uniform', activation = 'relu')\n",
    "\n",
    "def model_fn_9():\n",
    "  return model_fn(9)\n",
    "\n",
    "def model_fn_9_mod():\n",
    "  return model_fn(9, initializer = 'glorot_uniform', activation = 'relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Sc8xDdk2RTp"
   },
   "source": [
    "## Federated Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GGvMq3ATosV"
   },
   "source": [
    "### Original Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgodbIMsH2b9"
   },
   "source": [
    "#### Create Learning Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "K3k21nSQ9P-D"
   },
   "outputs": [],
   "source": [
    "# Create iterative learning process which will perform the federated learning\n",
    "iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "    model_fn_9,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.8),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NBMUBG1tHFfC",
    "outputId": "2d7c9dd3-9668-4f61-bd46-937ff749917e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( -> <\n",
      "  global_model_weights=<\n",
      "    trainable=<\n",
      "      float32[9,16],\n",
      "      float32[16],\n",
      "      float32[16,6],\n",
      "      float32[6],\n",
      "      float32[6,1],\n",
      "      float32[1]\n",
      "    >,\n",
      "    non_trainable=<>\n",
      "  >,\n",
      "  distributor=<>,\n",
      "  client_work=<>,\n",
      "  aggregator=<\n",
      "    value_sum_process=<>,\n",
      "    weight_sum_process=<>\n",
      "  >,\n",
      "  finalizer=<\n",
      "    int64,\n",
      "    float32[9,16],\n",
      "    float32[16],\n",
      "    float32[16,6],\n",
      "    float32[6],\n",
      "    float32[6,1],\n",
      "    float32[1]\n",
      "  >\n",
      ">@SERVER)\n"
     ]
    }
   ],
   "source": [
    "# The initial setup of the learning process\n",
    "print(iterative_process.initialize.type_signature.formatted_representation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1A-Lx1oGH9Jy"
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "kuAoyOYNbyr5"
   },
   "outputs": [],
   "source": [
    "state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QSqO7EPIHQXJ",
    "outputId": "f51ba4a9-6cea-4e68-91bd-904c230f6eed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:09<00:00,  1.11s/it]\n"
     ]
    }
   ],
   "source": [
    "# Train the federated model with random clients\n",
    "for round_num in tqdm.tqdm(range(1, NUM_ROUNDS)):\n",
    "    result = iterative_process.next(state, [f[0] for f in random_client_ds])\n",
    "    state = result.state\n",
    "    metrics = result.metrics\n",
    "    for name, value in metrics['client_work']['train'].items():\n",
    "        tf.summary.scalar(name, value, step=round_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03Kpx2vpWhQY",
    "outputId": "aaa52c08-1817-4d5d-c867-5b30fecf3de6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('distributor', ()),\n",
       "             ('client_work',\n",
       "              OrderedDict([('train',\n",
       "                            OrderedDict([('mean_absolute_error', 11003.576),\n",
       "                                         ('loss', 11003.577),\n",
       "                                         ('num_examples', 6280),\n",
       "                                         ('num_batches', 628)]))])),\n",
       "             ('aggregator',\n",
       "              OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
       "             ('finalizer', OrderedDict([('update_non_finite', 0)]))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OhYfnkG4T1qf",
    "outputId": "69a76d94-e24d-443a-8387-2152793542b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LearningAlgorithmState(global_model_weights=ModelWeights(trainable=[array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32), array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]], dtype=float32), array([0., 0., 0., 0., 0., 0.], dtype=float32), array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32), array([3058.2095], dtype=float32)], non_trainable=[]), distributor=(), client_work=(), aggregator=OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())]), finalizer=ListWrapper([9, array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32), array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]], dtype=float32), array([-0., -0., -0., -0., -0., -0.], dtype=float32), array([[-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.]], dtype=float32), array([269.3884], dtype=float32)]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.state\n",
    "# all weights are zero\n",
    "# -> nothing is learned "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqkadG5nH_KU"
   },
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "XwZd8b3FHjuh"
   },
   "outputs": [],
   "source": [
    "# Create the test data for model evaluation\n",
    "X_test = pd.concat([f[1][0] for f in random_client_ds])\n",
    "y_test = pd.concat([f[1][1] for f in random_client_ds])\n",
    "\n",
    "test_sets = [tf.data.Dataset.from_tensor_slices(\n",
    "    (tf.convert_to_tensor(np.expand_dims(el[1][0], axis=0)), \n",
    "    tf.convert_to_tensor(np.expand_dims(el[1][1], axis=0)))) \n",
    "    for el in random_client_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wl-0NiBSJDuO",
    "outputId": "10728282-5ca5-4cd0-9e33-e09d1436c1d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-43-552d4a23315f>:2: DeprecationWarning: `tff.learning.build_federated_evaluation` is deprecated, use `tff.learning.algorithms.build_fed_eval` instead.\n",
      "  evaluation = tff.learning.build_federated_evaluation(model_fn_9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('eval',\n",
       "              OrderedDict([('mean_absolute_error', 10782.501),\n",
       "                           ('loss', 10782.502),\n",
       "                           ('num_examples', 80),\n",
       "                           ('num_batches', 4)]))])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model evaluation\n",
    "evaluation = tff.learning.build_federated_evaluation(model_fn_9)\n",
    "# print(evaluation.type_signature.formatted_representation())\n",
    "model_weights = iterative_process.get_model_weights(state)\n",
    "train_metrics = evaluation(model_weights, test_sets)\n",
    "train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHtfuogKJe6z",
    "outputId": "937afb17-c9b5-45b0-f9b5-c92b9d72246c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 8ms/step - loss: 10782.5020 - mae: 10782.5020 - mean_squared_error: 264664192.0000\n",
      "[10782.501953125, 10782.501953125, 264664192.0]\n",
      "['loss', 'mae', 'mean_squared_error']\n"
     ]
    }
   ],
   "source": [
    "# Create model from training results and evaluate\n",
    "model = create_keras_model(input_features = 9)\n",
    "model_weights.assign_weights_to(model)\n",
    "model.compile(\n",
    "    loss=tf.losses.mae,\n",
    "    optimizer=tf.optimizers.Adam(),\n",
    "    metrics=[\"mae\", 'mean_squared_error']\n",
    ")\n",
    "# The evaluation results, for technical reasons the metrics_names is called afterwards. However, its order fits to the results\n",
    "print(model.evaluate(X_test, y_test))\n",
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-5ZQ6AyUpyX"
   },
   "source": [
    "### Test New Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLjpPo1sU3A2"
   },
   "source": [
    "#### Create Learning Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "FdUZhFGBUv6z"
   },
   "outputs": [],
   "source": [
    "# Create iterative learning process which will perform the federated learning\n",
    "iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "    model_fn_9_mod,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KNmoEYFdUv61",
    "outputId": "3eb6cf22-8411-45cb-a8cc-aa987b565916"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( -> <\n",
      "  global_model_weights=<\n",
      "    trainable=<\n",
      "      float32[5,16],\n",
      "      float32[16],\n",
      "      float32[16,6],\n",
      "      float32[6],\n",
      "      float32[6,1],\n",
      "      float32[1]\n",
      "    >,\n",
      "    non_trainable=<>\n",
      "  >,\n",
      "  distributor=<>,\n",
      "  client_work=<>,\n",
      "  aggregator=<\n",
      "    value_sum_process=<>,\n",
      "    weight_sum_process=<>\n",
      "  >,\n",
      "  finalizer=<\n",
      "    int64,\n",
      "    float32[5,16],\n",
      "    float32[16],\n",
      "    float32[16,6],\n",
      "    float32[6],\n",
      "    float32[6,1],\n",
      "    float32[1]\n",
      "  >\n",
      ">@SERVER)\n"
     ]
    }
   ],
   "source": [
    "# The initial setup of the learning process\n",
    "print(iterative_process.initialize.type_signature.formatted_representation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Q8XzfXlU5q5"
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "ROyd0BlXb2xr"
   },
   "outputs": [],
   "source": [
    "state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lEUgryWFU5q6",
    "outputId": "c455e9df-2b75-4a01-bcce-e4ce1e681906"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 149/149 [01:43<00:00,  1.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# Train the federated model with random clients\n",
    "for round_num in tqdm.tqdm(range(1, NUM_ROUNDS)):\n",
    "    result = iterative_process.next(state, [f[0] for f in random_client_ds])\n",
    "    state = result.state\n",
    "    metrics = result.metrics\n",
    "    for name, value in metrics['client_work']['train'].items():\n",
    "        tf.summary.scalar(name, value, step=round_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4TwFehjaXOGp",
    "outputId": "22d4a618-c072-4bc9-c7e0-f866eff97cbd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('distributor', ()),\n",
       "             ('client_work',\n",
       "              OrderedDict([('train',\n",
       "                            OrderedDict([('mean_absolute_error', 3807.3447),\n",
       "                                         ('loss', 3807.3452),\n",
       "                                         ('num_examples', 6280),\n",
       "                                         ('num_batches', 628)]))])),\n",
       "             ('aggregator',\n",
       "              OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
       "             ('finalizer', OrderedDict([('update_non_finite', 0)]))])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x3opn587U5q8",
    "outputId": "ee81f99d-c777-4625-9ef8-2fd71abbcdc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LearningAlgorithmState(global_model_weights=ModelWeights(trainable=[array([[ 1.0314033e+00,  3.9661708e+00, -1.6035627e-01, -5.5738455e-01,\n",
       "        -3.3340264e-02,  7.6503474e-01,  8.2155237e+00,  3.8735539e-01,\n",
       "         2.7853245e+01,  2.8849010e+01,  2.9533479e-01, -1.5679827e-01,\n",
       "         1.0196646e+00,  3.4656518e+00,  2.4119183e+01,  8.1142206e+00],\n",
       "       [ 7.5573564e-01, -1.2467850e+00, -3.1156147e-01, -8.0819167e-03,\n",
       "        -5.8784224e-02,  6.8030429e-01,  3.4803073e+00,  6.5711129e-01,\n",
       "        -2.1786277e+00, -1.7087191e+00,  3.9536785e-02, -2.1266997e-01,\n",
       "         1.0941437e+00, -8.0068648e-01,  2.8550303e+00, -1.4876491e+00],\n",
       "       [-1.1061091e+00,  1.5479072e+00,  3.0361131e-01,  1.4527263e-01,\n",
       "         7.6374221e+00,  2.7178215e+01,  2.9054230e-01,  2.8993628e+01,\n",
       "         6.8207771e-02,  3.5428636e+00,  3.3488023e+00, -1.3137506e+00,\n",
       "         4.1254173e+01, -1.4898837e-02,  5.9636884e+00, -4.1989894e+00],\n",
       "       [ 1.3273600e+00,  6.9692177e-01,  5.4167647e-02, -5.5476022e-01,\n",
       "        -1.2242582e+00, -2.6644659e-01, -8.3746690e-01, -5.4070824e-01,\n",
       "         1.4568372e+01, -4.1310596e+00, -5.4156816e-01, -3.3306196e-01,\n",
       "        -6.2379569e-01,  2.6726489e+00, -7.8412890e+00,  7.1804657e+00],\n",
       "       [-1.0647225e+00, -8.0918765e-01, -2.9251676e-02,  1.7492387e-01,\n",
       "         5.2531743e+00,  2.8213566e+01,  2.7351689e-01,  2.9770515e+01,\n",
       "        -6.6039457e+00,  5.6818852e+00,  3.0004351e+00,  7.5698686e-01,\n",
       "         4.2627300e+01, -6.5321869e-01,  5.6591649e+00,  2.5229642e-01],\n",
       "       [-1.7652669e+00,  7.3034310e+00, -2.5043953e-02, -1.4480361e-01,\n",
       "        -1.3758433e+00, -4.0325942e+00, -7.0281321e-01, -4.2371802e+00,\n",
       "         2.7615759e+00, -2.1540020e+00, -5.9063315e-01,  1.0978537e-02,\n",
       "        -6.4198980e+00, -3.2975295e+00, -3.3029463e+00, -8.0793409e+00],\n",
       "       [-3.6747587e-01, -6.1422315e+00, -2.3679661e-02,  3.6685643e-01,\n",
       "        -2.0179071e+00, -5.4743943e+00, -1.6082864e+00, -5.9242229e+00,\n",
       "        -2.3660865e+00, -2.8296158e+00, -1.3998438e+00,  9.1646969e-02,\n",
       "        -8.6075201e+00,  7.8365698e+00, -6.3366690e+00,  5.3675227e+00],\n",
       "       [ 6.5494102e-01, -6.2088537e+00, -2.8918758e-01, -1.4130510e-01,\n",
       "        -1.3720174e+00, -5.4040704e+00,  1.4741442e-01, -5.9591889e+00,\n",
       "        -2.7517302e+00, -2.4319968e+00, -4.8183724e-01,  2.5813637e-02,\n",
       "        -8.5351934e+00, -2.9366019e+00, -1.6291307e+00,  8.7015963e+00],\n",
       "       [ 1.5491670e+00,  5.7903242e+00, -3.7223402e-01,  7.3889658e-02,\n",
       "        -8.6840045e-01, -2.7633085e+00, -1.8512592e+00, -3.1056619e+00,\n",
       "        -5.2323395e-01, -3.7554672e+00, -4.1215706e-01, -2.3306714e-01,\n",
       "        -4.5197549e+00, -3.3457212e+00,  1.4914297e-01, -7.8373594e+00]],\n",
       "      dtype=float32), array([ -0.39658362,   1.3323036 ,  -0.1749945 ,  -0.17248094,\n",
       "        -4.944066  , -18.381672  ,  -3.7822762 , -19.11623   ,\n",
       "        -2.9173634 , -12.307355  ,  -2.5330873 ,   0.08329192,\n",
       "       -27.586731  ,  -1.8664949 , -10.796182  ,  -1.3881837 ],\n",
       "      dtype=float32), array([[-2.16119766e-01, -1.48887873e-01,  1.15997806e-01,\n",
       "         2.69319624e-01, -4.54167455e-01,  1.04988015e+00],\n",
       "       [-3.90860051e-01, -3.90359461e-01, -3.98642302e-01,\n",
       "         3.44498563e+00, -3.04647684e-01,  5.91972208e+00],\n",
       "       [-1.83291540e-01,  2.92936146e-01,  9.72678959e-02,\n",
       "        -4.42875862e-01,  2.93175787e-01, -1.56759262e-01],\n",
       "       [-6.44162819e-02, -3.62672448e-01,  5.48896305e-02,\n",
       "        -4.53648090e-01, -5.12348354e-01, -3.60936159e-03],\n",
       "       [ 3.20020258e-01,  4.68792140e-01, -7.29708523e-02,\n",
       "         1.76933658e+00, -5.21864772e-01,  3.31154156e+00],\n",
       "       [-4.95653152e-01,  1.48870707e+00,  4.12193477e-01,\n",
       "         8.06298542e+00, -1.45915046e-01,  1.16796951e+01],\n",
       "       [ 4.77446020e-02,  4.17308390e-01,  4.02956218e-01,\n",
       "         1.66944468e+00, -4.26614493e-01,  1.87767363e+00],\n",
       "       [-4.09551948e-01,  1.23973382e+00, -4.96427804e-01,\n",
       "         8.39357281e+00,  4.35532033e-01,  1.24588385e+01],\n",
       "       [-3.36310565e-01, -1.82065296e+00, -1.66800588e-01,\n",
       "         5.25254345e+00,  1.42406235e-02,  7.27036858e+00],\n",
       "       [-1.94945365e-01,  6.01975560e-01, -4.90415037e-01,\n",
       "         3.37001681e+00,  1.81621835e-01,  4.90817404e+00],\n",
       "       [-2.36293271e-01,  2.47019872e-01,  2.43130237e-01,\n",
       "         1.20552421e+00, -5.55374064e-02,  1.26812398e+00],\n",
       "       [-4.83381391e-01,  5.74269053e-03,  1.93691730e-01,\n",
       "        -2.54147559e-01,  1.18213100e-02, -6.55414462e-01],\n",
       "       [ 3.63262862e-01,  2.40425253e+00, -3.98889512e-01,\n",
       "         1.24569960e+01, -2.62870640e-01,  1.74254456e+01],\n",
       "       [ 4.19593036e-01,  2.25480899e-01,  1.32096320e-01,\n",
       "         3.44659662e+00, -3.27812225e-01,  4.32268476e+00],\n",
       "       [-2.24509686e-01,  1.48964870e+00,  2.09702998e-01,\n",
       "         3.26906776e+00, -5.30343950e-01,  5.16745949e+00],\n",
       "       [-2.79245228e-01, -6.12571776e-01, -2.03182265e-01,\n",
       "         3.87388802e+00, -3.15326303e-01,  5.30539513e+00]], dtype=float32), array([-2.5437025e-02,  2.2128068e-01, -2.0530623e-01,  1.8654722e+01,\n",
       "       -8.5426904e-02,  2.6809139e+01], dtype=float32), array([[-0.55705255],\n",
       "       [ 3.1300797 ],\n",
       "       [-0.84919965],\n",
       "       [15.899075  ],\n",
       "       [-0.6668146 ],\n",
       "       [22.875147  ]], dtype=float32), array([2.0578485], dtype=float32)], non_trainable=[]), distributor=(), client_work=(), aggregator=OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())]), finalizer=ListWrapper([178, array([[ 1.16080623e-02,  5.00833765e-02, -4.68697453e-06,\n",
       "        -1.31722761e-03, -5.01408335e-03, -2.09199209e-02,\n",
       "         2.94222739e-02, -1.73321404e-02,  1.37038231e-02,\n",
       "         2.42574941e-02, -3.71169602e-03,  2.31553777e-03,\n",
       "        -3.09107546e-02,  1.34799574e-02,  1.95711851e-02,\n",
       "         8.76585171e-02],\n",
       "       [-1.81113295e-02, -2.90102270e-02,  0.00000000e+00,\n",
       "         9.87165957e-04,  6.49417145e-03, -8.02144315e-03,\n",
       "         3.15394215e-02, -1.00884391e-02, -4.65016719e-03,\n",
       "        -1.97441187e-02, -6.74495299e-04, -1.39645126e-03,\n",
       "        -1.13902315e-02,  1.31237675e-02,  4.51555802e-03,\n",
       "        -1.78922284e-02],\n",
       "       [-9.98140965e-03, -1.33377512e-03, -1.37204304e-04,\n",
       "        -9.14922741e-04,  2.63278242e-02,  5.20174503e-02,\n",
       "        -1.43664079e-02,  5.69878593e-02, -4.10584994e-02,\n",
       "        -2.96181869e-02,  9.60288104e-03, -4.71444009e-03,\n",
       "         7.91734308e-02,  4.53442708e-03, -3.01430523e-02,\n",
       "        -3.52540836e-02],\n",
       "       [-2.35593622e-03,  2.46473327e-02, -4.31189364e-05,\n",
       "        -1.09435921e-03, -4.61074943e-03,  1.60484668e-02,\n",
       "        -1.08705601e-02,  1.88551005e-02,  2.57281214e-03,\n",
       "        -3.03347446e-02, -3.64964386e-03, -1.09064661e-03,\n",
       "         2.45519858e-02,  1.13203237e-02, -4.24692594e-02,\n",
       "         4.42243740e-02],\n",
       "       [-4.45143273e-03,  5.14643965e-03,  0.00000000e+00,\n",
       "        -2.25329446e-03,  1.51148504e-02,  6.09226003e-02,\n",
       "        -1.91918798e-02,  6.28360733e-02, -2.19282042e-02,\n",
       "        -1.92537513e-02,  9.72256006e-04,  1.61336444e-03,\n",
       "         9.33415443e-02, -1.16312392e-02, -2.89042834e-02,\n",
       "         2.21627988e-02],\n",
       "       [-7.42206001e-04,  3.67082618e-02,  0.00000000e+00,\n",
       "        -1.09576991e-04, -4.08719853e-03, -7.77308783e-03,\n",
       "         1.29971253e-02, -8.84496793e-03,  1.45761222e-02,\n",
       "         1.80264171e-02, -2.32991646e-03, -2.78040592e-04,\n",
       "        -1.13200238e-02, -1.73583049e-02, -3.13443430e-02,\n",
       "        -3.71080600e-02],\n",
       "       [-1.54093895e-02, -3.29798758e-02, -2.15594613e-04,\n",
       "         6.33786200e-04,  9.52497299e-04, -1.37991551e-02,\n",
       "        -4.16161446e-03, -1.51433945e-02, -3.62966396e-02,\n",
       "         3.61383967e-02, -2.24764785e-03,  2.76006613e-04,\n",
       "        -2.05671806e-02,  3.36175896e-02,  1.16302660e-02,\n",
       "        -4.27970551e-02],\n",
       "       [ 5.00164693e-03, -2.97098160e-02,  0.00000000e+00,\n",
       "        -1.07526968e-04, -6.74402853e-03, -4.51672189e-02,\n",
       "        -5.01222676e-04, -5.33891097e-02, -1.65589079e-02,\n",
       "        -1.45584932e-02, -4.56111412e-03,  5.39284025e-04,\n",
       "        -6.78403974e-02, -3.61830033e-02, -3.21793072e-02,\n",
       "         5.19100539e-02],\n",
       "       [ 2.03937897e-03,  4.88262856e-03,  0.00000000e+00,\n",
       "         1.71907395e-05, -4.20782808e-03, -4.65572858e-03,\n",
       "        -9.35666822e-03,  4.56781685e-03,  4.31944150e-03,\n",
       "        -6.61434010e-02, -3.41010909e-03,  7.12407462e-04,\n",
       "        -6.78106630e-03, -1.39270425e-02,  1.64976772e-02,\n",
       "        -1.15328683e-02]], dtype=float32), array([-0.00911056, -0.02109892, -0.00021559,  0.00043388, -0.01408657,\n",
       "       -0.07139533, -0.00102244, -0.07280958, -0.03395997, -0.02653712,\n",
       "       -0.01254883,  0.00124966, -0.10650826, -0.03385084, -0.03539567,\n",
       "       -0.03952794], dtype=float32), array([[ 7.6927719e-08, -5.6024477e-05,  2.7444214e-05, -1.7678207e-03,\n",
       "         0.0000000e+00, -2.6990788e-03],\n",
       "       [ 0.0000000e+00, -4.5631040e-04,  0.0000000e+00,  5.6318077e-03,\n",
       "         0.0000000e+00,  6.3122632e-03],\n",
       "       [-3.3713878e-08,  0.0000000e+00, -2.5704503e-08,  7.8603625e-07,\n",
       "         0.0000000e+00,  1.1300668e-06],\n",
       "       [ 1.9838662e-05,  1.2064390e-04, -6.1723542e-05, -1.0490899e-03,\n",
       "         0.0000000e+00, -1.4990655e-03],\n",
       "       [ 0.0000000e+00,  1.6848646e-03,  0.0000000e+00,  2.7498619e-03,\n",
       "         0.0000000e+00,  3.8872273e-03],\n",
       "       [-3.8445371e-05,  1.1712749e-02,  0.0000000e+00,  3.8070621e-03,\n",
       "         2.0171516e-05,  5.1958081e-03],\n",
       "       [-2.3982527e-04,  4.7189193e-03, -4.5297630e-04, -1.2469840e-03,\n",
       "         0.0000000e+00, -1.7921355e-03],\n",
       "       [-4.1164833e-05,  1.2826438e-02,  0.0000000e+00,  4.8129200e-03,\n",
       "         4.4769793e-05,  6.6295862e-03],\n",
       "       [-3.8522444e-04, -1.5423456e-02, -2.2192467e-04, -5.5078561e-03,\n",
       "         0.0000000e+00, -8.4712571e-03],\n",
       "       [ 0.0000000e+00, -3.6623869e-03,  2.3097749e-08, -1.0618615e-02,\n",
       "         0.0000000e+00, -1.5178380e-02],\n",
       "       [ 0.0000000e+00,  7.5711124e-04,  9.0152025e-07,  6.3553496e-05,\n",
       "         5.0938688e-06,  5.6152039e-05],\n",
       "       [-3.9666893e-06, -6.6600885e-05, -1.2643635e-06, -4.6083611e-04,\n",
       "         0.0000000e+00, -6.5103470e-04],\n",
       "       [-5.7915600e-05,  1.7645014e-02,  0.0000000e+00,  5.7869805e-03,\n",
       "         3.1421336e-05,  7.8990115e-03],\n",
       "       [-4.5587911e-04,  3.5014810e-04, -2.0628066e-03,  6.0555730e-03,\n",
       "         0.0000000e+00,  9.7921770e-03],\n",
       "       [ 3.3793972e-06,  7.2658435e-03, -2.2870317e-05, -2.1054128e-02,\n",
       "         0.0000000e+00, -3.0684153e-02],\n",
       "       [ 2.4769604e-04, -3.6510124e-03, -5.1442737e-04, -7.4801492e-03,\n",
       "         1.4344230e-05, -9.3103824e-03]], dtype=float32), array([-2.6060038e-04,  3.4072082e-03, -5.8279163e-04,  7.4787959e-02,\n",
       "        8.3351506e-06,  1.0739555e-01], dtype=float32), array([[ 3.1116753e-04],\n",
       "       [ 2.2867469e-02],\n",
       "       [ 1.7617269e-04],\n",
       "       [-5.1180362e-03],\n",
       "       [-4.1596591e-06],\n",
       "       [-8.3074085e-03]], dtype=float32), array([0.00787497], dtype=float32)]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.state\n",
    "# all weights are zero\n",
    "# -> nothing is learned "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWHGNcN-VA98"
   },
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "1qAVD1haVA9-"
   },
   "outputs": [],
   "source": [
    "# Create the test data for model evaluation\n",
    "X_test = pd.concat([f[1][0] for f in federated_insurance_data])\n",
    "y_test = pd.concat([f[1][1] for f in federated_insurance_data])\n",
    "\n",
    "test_sets = [tf.data.Dataset.from_tensor_slices(\n",
    "    (tf.convert_to_tensor(np.expand_dims(el[1][0], axis=0)), \n",
    "    tf.convert_to_tensor(np.expand_dims(el[1][1], axis=0)))) \n",
    "    for el in federated_insurance_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xHTiYD-nVA9_",
    "outputId": "75f27284-a319-4ed9-ffe6-7e04db33adb8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-fe93b6610415>:2: DeprecationWarning: `tff.learning.build_federated_evaluation` is deprecated, use `tff.learning.algorithms.build_fed_eval` instead.\n",
      "  evaluation = tff.learning.build_federated_evaluation(model_fn_5_mod)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('eval',\n",
       "              OrderedDict([('mean_absolute_error', nan),\n",
       "                           ('loss', 0.0),\n",
       "                           ('num_examples', 0),\n",
       "                           ('num_batches', 3)]))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model evaluation\n",
    "evaluation = tff.learning.build_federated_evaluation(model_fn_5_mod)\n",
    "# print(evaluation.type_signature.formatted_representation())\n",
    "model_weights = iterative_process.get_model_weights(state)\n",
    "train_metrics = evaluation(model_weights, test_sets)\n",
    "train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "-NKLXp9aiDqA"
   },
   "outputs": [],
   "source": [
    "r2scr = RSquare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ob4g5OHuVA-A",
    "outputId": "25f5c583-502f-4de7-f0cf-672b62489be2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 7ms/step - loss: 10782.5020 - mae: 10782.5020 - mean_squared_error: 264664192.0000\n",
      "[10782.501953125, 10782.501953125, 264664192.0]\n",
      "['loss', 'mae', 'mean_squared_error']\n"
     ]
    }
   ],
   "source": [
    "# Create model from training results and evaluate\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model = create_keras_model(input_features = 9)\n",
    "model_weights.assign_weights_to(model)\n",
    "model.compile(\n",
    "    loss=tf.losses.mae,\n",
    "    optimizer=tf.optimizers.SGD(),\n",
    "    metrics=[\"mae\", 'mean_squared_error'#, r2_score\n",
    "             ]\n",
    ")\n",
    "\n",
    "# The evaluation results, for technical reasons the metrics_names is called afterwards. However, its order fits to the results\n",
    "print(model.evaluate(X_test, y_test))\n",
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_9XHZx0XddY"
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mI5W1ESJXe4z"
   },
   "source": [
    "- the original repo uses a totally different model as in centralized learning.\n",
    "  - linear\n",
    "  - no learning by zero initializer\n",
    "- new learner cuts mae ~66%\n",
    "- how to calculate RSquare?\n",
    "- error: no learning occurs (for clients). Empty?\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOpiH28DbWZ87vjm1Ef3Jw7",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
