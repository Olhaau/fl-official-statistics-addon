{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPRNKZM4k3O+Zt26uZJmzjc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Olhaau/fl-official-statistics-addon/blob/main/_dev/03_insurance_federated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Medical Insurance - a Federated Learning Use Case.\n",
        "\n",
        "This notebook contains Federated Learning.\n",
        "\n",
        "-- **tba** --"
      ],
      "metadata": {
        "id": "Z1N2mtyx2Uxs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "---"
      ],
      "metadata": {
        "id": "2qdJnO4M7VDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pull Repo"
      ],
      "metadata": {
        "id": "aZQgDGzbd3pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# rm repo from gdrive\n",
        "if os.path.exists(\"fl-official-statistics-addon\"):\n",
        "  %rm -r fl-official-statistics-addon\n",
        "\n",
        "# clone\n",
        "!git clone https://github.com/Olhaau/fl-official-statistics-addon\n",
        "%cd fl-official-statistics-addon\n",
        "\n",
        "# pull (the currenct version of the repo)\n",
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5qBP638d0iR",
        "outputId": "0ac19e91-f318-46a3-ad88-bbc081aa9e6b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fl-official-statistics-addon'...\n",
            "remote: Enumerating objects: 682, done.\u001b[K\n",
            "remote: Counting objects: 100% (318/318), done.\u001b[K\n",
            "remote: Compressing objects: 100% (179/179), done.\u001b[K\n",
            "remote: Total 682 (delta 153), reused 288 (delta 133), pack-reused 364\u001b[K\n",
            "Receiving objects: 100% (682/682), 32.22 MiB | 13.67 MiB/s, done.\n",
            "Resolving deltas: 100% (276/276), done.\n",
            "Updating files: 100% (275/275), done.\n",
            "/content/fl-official-statistics-addon\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installs"
      ],
      "metadata": {
        "id": "1d5TMrK67Xxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  !pip install --quiet nest_asyncio\n",
        "  !pip install --quiet tensorflow_federated\n",
        "  !pip install --quiet tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQSYlSd47WaM",
        "outputId": "6511feb4-4c93-4e15-b090-3be887505fe2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.3/71.3 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.2/120.2 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 KB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.8/243.8 KB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.1/990.1 KB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.0/349.0 KB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.7/126.7 KB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.6/532.6 KB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.8/39.8 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pymc 5.1.2 requires cachetools>=4.2.1, but you have cachetools 3.1.1 which is incompatible.\n",
            "google-colab 1.0.0 requires portpicker~=1.3.1, but you have portpicker 1.5.2 which is incompatible.\n",
            "arviz 0.15.1 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "nUcRlUPV7bZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tqdm\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "from tensorflow_addons.metrics import RSquare\n",
        "import tensorflow_addons as tfa\n",
        "import nest_asyncio\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "id": "2zMmbNFf7Wc6"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ingest and Split the Data"
      ],
      "metadata": {
        "id": "XxFNFscq8O74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"output/data/insurance-clean.csv\", index_col = 0)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "C9zyHqiN9fCo",
        "outputId": "b004f804-780e-499d-f5d2-ccf1445a50f2"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        age  sex       bmi  children  smoker     region      charges  region0  \\\n",
              "0  0.021739  0.0  0.321227       0.0     1.0  southwest  16884.92400      0.0   \n",
              "1  0.000000  1.0  0.479150       0.2     0.0  southeast   1725.55230      0.0   \n",
              "2  0.217391  1.0  0.458434       0.6     0.0  southeast   4449.46200      0.0   \n",
              "3  0.326087  1.0  0.181464       0.0     0.0  northwest  21984.47061      0.0   \n",
              "4  0.304348  1.0  0.347592       0.0     0.0  northwest   3866.85520      0.0   \n",
              "\n",
              "   region1  region2  region3  \n",
              "0      0.0      0.0      1.0  \n",
              "1      0.0      1.0      0.0  \n",
              "2      0.0      1.0      0.0  \n",
              "3      1.0      0.0      0.0  \n",
              "4      1.0      0.0      0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-188c385f-985d-4fb3-af87-bdef619b3558\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "      <th>region0</th>\n",
              "      <th>region1</th>\n",
              "      <th>region2</th>\n",
              "      <th>region3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.021739</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.321227</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.479150</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.217391</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.458434</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.326087</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.181464</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.304348</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.347592</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-188c385f-985d-4fb3-af87-bdef619b3558')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-188c385f-985d-4fb3-af87-bdef619b3558 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-188c385f-985d-4fb3-af87-bdef619b3558');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 4\n",
        "NUM_EPOCHS = 5\n",
        "BATCH_SIZE = 10\n",
        "SHUFFLE_BUFFER = 20\n",
        "PREFETCH_BUFFER = 5\n",
        "NUM_ROUNDS = 150\n",
        "RUN_NAME = f'0,8-3({NUM_ROUNDS})-{NUM_EPOCHS}-epochs-{BATCH_SIZE}-batch-WithRegion/'"
      ],
      "metadata": {
        "id": "Qam6babo7Wgg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "syn_samples_per_region = 1000\n",
        "\n",
        "def get_dataset_for_region(dataset, region_index, test_size_per_region=20):\n",
        "    \"\"\"Min-max scale and return data for a single, given region. The scaler must be fitted before.\n",
        "\n",
        "    :param dataset: The dataset to get the regional data from\n",
        "    :type dataset: pandas.DataFrame\n",
        "    :param region_index: The index number of the region to return\n",
        "    :type region_index: int\n",
        "    :param test_size_per_region: The amount of values to separate for testing, default are 20\n",
        "    :type test_size_per_region: int, optional\n",
        "    :return: The dataset specific for the defined region, the test values, the test labels\n",
        "    :rtype: tensorflow.python.data.ops.dataset_ops.PrefetchDataset, tuple of pandas.core.series.Series\n",
        "    \"\"\"\n",
        "    region_ds = dataset[dataset['region'] == region_index]\n",
        "    region_ds = region_ds.drop(columns=['region'])\n",
        "    len = region_ds.shape[0]\n",
        "\n",
        "    # The scaling into [0, 1] is not necessary anymore, it happens when the data loads already\n",
        "    # region_ds[['age', 'bmi', 'children']] = scaler.transform(region_ds[['age', 'bmi', 'children']])\n",
        "\n",
        "    X_test = region_ds.head(test_size_per_region)\n",
        "    y_test = X_test.pop('charges')\n",
        "\n",
        "    X_train = region_ds.tail(len - test_size_per_region)\n",
        "    y_train = X_train.pop('charges')\n",
        "\n",
        "    fed_train_dataset = tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(X_train), tf.convert_to_tensor(y_train)))\n",
        "\n",
        "    return (\n",
        "        fed_train_dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER, seed=1).batch(BATCH_SIZE).prefetch(PREFETCH_BUFFER),\n",
        "        (X_test, y_test)\n",
        "    )"
      ],
      "metadata": {
        "id": "JTutbOjq8VzQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create test and train sets and put them into random_client_ds, use four clients which are independent of the region\n",
        "def get_dataset_random_region(dataset, num_clients=4, test_size_per_region=20):\n",
        "    \"\"\"Creates a list with client datasets independent of the region.\n",
        "\n",
        "    :param dataset: The dataset to get the regional data from\n",
        "    :type dataset: pandas.DataFrame\n",
        "    :param num_clients: the number of clients create (equal big datasets per client), default value is 4 clients\n",
        "    :type num_clients: int, optional\n",
        "    :param test_size_per_region: The amount of values to separate for testing, default are 20\n",
        "    :type test_size_per_region: int, optional\n",
        "    :return: List of the prepared dataset with one entry per region, the test values and labels for each region\n",
        "    :rtype: List of (tensorflow.python.data.ops.dataset_ops.PrefetchDataset, tuple of pandas.core.series.Series)\"\"\"\n",
        "    size_of_client_ds = int(dataset.shape[0] / num_clients)\n",
        "\n",
        "    dataset_to_split = dataset.copy()\n",
        "    dataset_to_split.pop(\"region\")\n",
        "    random_client_ds = []\n",
        "    for i in range(num_clients):\n",
        "        sampled = dataset_to_split.sample(n=size_of_client_ds)\n",
        "        dataset_to_split.drop(sampled.index)\n",
        "\n",
        "        X_test = sampled.head(test_size_per_region)\n",
        "        y_test = X_test.pop('charges')\n",
        "\n",
        "        X_train = sampled.tail(size_of_client_ds - test_size_per_region)\n",
        "        y_train = X_train.pop('charges')\n",
        "\n",
        "        fed_train_dataset = tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(X_train), tf.convert_to_tensor(y_train)))\n",
        "\n",
        "        train_set = fed_train_dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER, seed=1).batch(BATCH_SIZE).prefetch(PREFETCH_BUFFER)\n",
        "        test_set = (X_test, y_test)\n",
        "\n",
        "        random_client_ds.append((train_set, test_set))\n",
        "\n",
        "    return random_client_ds"
      ],
      "metadata": {
        "id": "8FEwLlGv8eq3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data for clients with regional data (each client one region)\n",
        "test_size_per_region = 20\n",
        "regions = ['region0', 'region1', 'region2', 'region3']\n",
        "\n",
        "federated_insurance_data = [\n",
        "    get_dataset_for_region(df.drop(regions, axis=1), i, test_size_per_region=test_size_per_region)\n",
        "    for i in range(NUM_CLIENTS-1)]\n",
        "federated_insurance_data"
      ],
      "metadata": {
        "id": "Dirvrz6Y9ARK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data for clients with regional independent data\n",
        "random_client_ds = get_dataset_random_region(df, num_clients=NUM_CLIENTS, test_size_per_region=test_size_per_region)"
      ],
      "metadata": {
        "id": "mX6HRriR9Cil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code Tests"
      ],
      "metadata": {
        "id": "RiNQ6m66A7sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"splitted datasets: {}\".format(len(federated_insurance_data)))\n",
        "print(\"------------------------------\")\n",
        "# Q: why range(NUM_CLIENTS-1) and, thus, only 3 clients?\n",
        "\n",
        "# Q: how to output? -> does not work or nothing in it?\n",
        "list(federated_insurance_data[0][0].as_numpy_iterator())[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRbSvR-Q9058",
        "outputId": "fcac5e08-3c4a-4292-c625-65057b2ed48b"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "splitted datasets: 3\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Show Tensor"
      ],
      "metadata": {
        "id": "GJY8_tVdCXrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Tensor Object\n",
        "X_train = df.iloc[:,0:4]\n",
        "y_train = df['charges']\n",
        "df2 = tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(X_train), tf.convert_to_tensor(y_train)))\n",
        "df2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFohPc1rAqVw",
        "outputId": "e3695ee6-04b0-4db7-bc81-81903b7496e8"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset element_spec=(TensorSpec(shape=(4,), dtype=tf.float64, name=None), TensorSpec(shape=(), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show Tensor Object\n",
        "# S. https://stackoverflow.com/questions/62436302/extract-target-from-tensorflow-prefetchdataset\n",
        "list(df2.as_numpy_iterator())[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpW57hM4DOBI",
        "outputId": "d0bdd312-e7c8-4cc1-ed57-47b6087eeb0e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([0.02173913, 0.        , 0.3212268 , 0.        ]), 16884.924),\n",
              " (array([0.        , 1.        , 0.47914985, 0.2       ]), 1725.5523),\n",
              " (array([0.2173913 , 1.        , 0.45843422, 0.6       ]), 4449.462),\n",
              " (array([0.32608696, 1.        , 0.18146355, 0.        ]), 21984.47061),\n",
              " (array([0.30434783, 1.        , 0.34759214, 0.        ]), 3866.8552),\n",
              " (array([0.2826087 , 0.        , 0.26311542, 0.        ]), 3756.6216),\n",
              " (array([0.60869565, 0.        , 0.47027172, 0.2       ]), 8240.5896),\n",
              " (array([0.41304348, 0.        , 0.31692225, 0.6       ]), 7281.5056),\n",
              " (array([0.41304348, 1.        , 0.37315039, 0.4       ]), 6406.4107),\n",
              " (array([0.91304348, 0.        , 0.26580576, 0.        ]), 28923.13692)]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fx5SFZNkDptQ",
        "outputId": "db37d822-1ba3-4514-bb28-d9e7aa4a046f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Builder"
      ],
      "metadata": {
        "id": "2PvPyDQL8iXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_keras_model(\n",
        "    input_features = 9,\n",
        "    initializer = 'zeros',\n",
        "    units = [16,6,1],\n",
        "    activation = None\n",
        "    ):\n",
        "    \"\"\"Create neural network for given number of input features)\n",
        "\n",
        "    :param input_features: The dimension of the first layer with represents the amount of features used\n",
        "    :type input_features: int, optional\n",
        "    :return: Created but not compiled model\n",
        "    :rtype: keras.Model\n",
        "    \"\"\"\n",
        "    return tf.keras.models.Sequential([\n",
        "        # without region: tf.keras.layers.InputLayer(input_shape=(5,)),\n",
        "        tf.keras.layers.InputLayer(input_shape=(input_features,)),\n",
        "        tf.keras.layers.Dense(units[0], kernel_initializer=initializer, activation = activation\n",
        "                              ),\n",
        "        tf.keras.layers.Dense(units[1], kernel_initializer=initializer, activation = activation\n",
        "                              ),\n",
        "        tf.keras.layers.Dense(units[2], kernel_initializer=initializer)\n",
        "    ])\n",
        "\n",
        "\n",
        "# A helper function for federated learning\n",
        "def model_fn(    \n",
        "    input_features = 9,\n",
        "    initializer = 'zeros',\n",
        "    units = [16,6,1],\n",
        "    activation = None):\n",
        "    \"\"\"A function for TFF to create a local model during federated learning and return it as the correct type.\n",
        "    This model uses 9 input features i.e. the regions are part of the features.\n",
        "\n",
        "    :return: The LSTM model to be used as federated models\n",
        "    :rtype: tff.learning.Model\n",
        "    \"\"\"\n",
        "    # We _must_ create a new model here, and _not_ capture it from an external\n",
        "    # scope. TFF will call this within different graph contexts.\n",
        "    keras_model = create_keras_model(\n",
        "            input_features = input_features,\n",
        "            initializer = initializer,\n",
        "            activation = activation,\n",
        "            units = units\n",
        "    )\n",
        "    return tff.learning.from_keras_model(\n",
        "        keras_model,\n",
        "        # without region: \n",
        "        input_spec = federated_insurance_data[0][0].element_spec,\n",
        "        #input_spec = random_client_ds[0][0].element_spec,\n",
        "        loss = tf.keras.losses.MeanAbsoluteError(),\n",
        "        metrics = [tf.keras.metrics.MeanAbsoluteError()\n",
        "        #,tfa.metrics.RSquare()\n",
        "        ]\n",
        "    )\n",
        "\n",
        "# Helper functions for different features as input\n",
        "def model_fn_5():\n",
        "    return model_fn(5)\n",
        "\n",
        "def model_fn_5_mod():\n",
        "  return model_fn(5, initializer = 'glorot_uniform', activation = 'relu')\n",
        "\n",
        "def model_fn_9():\n",
        "  return model_fn(9)"
      ],
      "metadata": {
        "id": "9Csom8dD8hRK"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Federated Learning"
      ],
      "metadata": {
        "id": "6Sc8xDdk2RTp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Original Model"
      ],
      "metadata": {
        "id": "_GGvMq3ATosV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create Learning Process"
      ],
      "metadata": {
        "id": "GgodbIMsH2b9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create iterative learning process which will perform the federated learning\n",
        "iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn_5,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.8),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=3))"
      ],
      "metadata": {
        "id": "K3k21nSQ9P-D"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The initial setup of the learning process\n",
        "print(iterative_process.initialize.type_signature.formatted_representation())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBMUBG1tHFfC",
        "outputId": "4a217527-f250-43fd-9b9b-7ef94c2f81d9"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "( -> <\n",
            "  global_model_weights=<\n",
            "    trainable=<\n",
            "      float32[5,16],\n",
            "      float32[16],\n",
            "      float32[16,6],\n",
            "      float32[6],\n",
            "      float32[6,1],\n",
            "      float32[1]\n",
            "    >,\n",
            "    non_trainable=<>\n",
            "  >,\n",
            "  distributor=<>,\n",
            "  client_work=<>,\n",
            "  aggregator=<\n",
            "    value_sum_process=<>,\n",
            "    weight_sum_process=<>\n",
            "  >,\n",
            "  finalizer=<\n",
            "    int64,\n",
            "    float32[5,16],\n",
            "    float32[16],\n",
            "    float32[16,6],\n",
            "    float32[6],\n",
            "    float32[6,1],\n",
            "    float32[1]\n",
            "  >\n",
            ">@SERVER)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train"
      ],
      "metadata": {
        "id": "1A-Lx1oGH9Jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the federated model with random clients\n",
        "for round_num in tqdm.tqdm(range(1, NUM_ROUNDS)):\n",
        "    result = iterative_process.next(state, [f[0] for f in federated_insurance_data])\n",
        "    state = result.state\n",
        "    metrics = result.metrics\n",
        "    for name, value in metrics['client_work']['train'].items():\n",
        "        tf.summary.scalar(name, value, step=round_num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSqO7EPIHQXJ",
        "outputId": "853b240a-9bcf-4745-bf56-3811a46f8543"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 149/149 [00:30<00:00,  4.83it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03Kpx2vpWhQY",
        "outputId": "ed12fd41-4948-4cd0-9166-194b2a5a0c3d"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('distributor', ()),\n",
              "             ('client_work',\n",
              "              OrderedDict([('train',\n",
              "                            OrderedDict([('mean_absolute_error', 0.0),\n",
              "                                         ('loss', 0.0),\n",
              "                                         ('num_examples', 0),\n",
              "                                         ('num_batches', 0)]))])),\n",
              "             ('aggregator',\n",
              "              OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "             ('finalizer', OrderedDict([('update_non_finite', 1)]))])"
            ]
          },
          "metadata": {},
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.state\n",
        "# all weights are zero\n",
        "# -> nothing is learned "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhYfnkG4T1qf",
        "outputId": "4ac43717-574e-4976-adef-9c69c61efaa0"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LearningAlgorithmState(global_model_weights=ModelWeights(trainable=[array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "      dtype=float32), array([[0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.]], dtype=float32), array([0., 0., 0., 0., 0., 0.], dtype=float32), array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]], dtype=float32), array([0.], dtype=float32)], non_trainable=[]), distributor=(), client_work=(), aggregator=OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())]), finalizer=ListWrapper([0, array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "      dtype=float32), array([[0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.]], dtype=float32), array([0., 0., 0., 0., 0., 0.], dtype=float32), array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]], dtype=float32), array([0.], dtype=float32)]))"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate"
      ],
      "metadata": {
        "id": "eqkadG5nH_KU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the test data for model evaluation\n",
        "X_test = pd.concat([f[1][0] for f in federated_insurance_data])\n",
        "y_test = pd.concat([f[1][1] for f in federated_insurance_data])\n",
        "\n",
        "test_sets = [tf.data.Dataset.from_tensor_slices(\n",
        "    (tf.convert_to_tensor(np.expand_dims(el[1][0], axis=0)), \n",
        "    tf.convert_to_tensor(np.expand_dims(el[1][1], axis=0)))) \n",
        "    for el in federated_insurance_data]"
      ],
      "metadata": {
        "id": "XwZd8b3FHjuh"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation\n",
        "evaluation = tff.learning.build_federated_evaluation(model_fn_5)\n",
        "# print(evaluation.type_signature.formatted_representation())\n",
        "model_weights = iterative_process.get_model_weights(state)\n",
        "train_metrics = evaluation(model_weights, test_sets)\n",
        "train_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl-0NiBSJDuO",
        "outputId": "5fe9e5f4-23ac-493d-9861-00a8730d8426"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-193-8b7832a90ebf>:2: DeprecationWarning: `tff.learning.build_federated_evaluation` is deprecated, use `tff.learning.algorithms.build_fed_eval` instead.\n",
            "  evaluation = tff.learning.build_federated_evaluation(model_fn_5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('eval',\n",
              "              OrderedDict([('mean_absolute_error', nan),\n",
              "                           ('loss', 0.0),\n",
              "                           ('num_examples', 0),\n",
              "                           ('num_batches', 3)]))])"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model from training results and evaluate\n",
        "model = create_keras_model(input_features = 5)\n",
        "model_weights.assign_weights_to(model)\n",
        "model.compile(\n",
        "    loss=tf.losses.mae,\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    metrics=[\"mae\", 'mean_squared_error']\n",
        ")\n",
        "# The evaluation results, for technical reasons the metrics_names is called afterwards. However, its order fits to the results\n",
        "#print(model.evaluate(X_test, y_test))\n",
        "print(model.metrics_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHtfuogKJe6z",
        "outputId": "41ccd766-e69c-45c1-c099-ab29a0ce2efc"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Real Learner"
      ],
      "metadata": {
        "id": "J-5ZQ6AyUpyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create Learning Process"
      ],
      "metadata": {
        "id": "dLjpPo1sU3A2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create iterative learning process which will perform the federated learning\n",
        "iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn_5_mod,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.01),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=.05))"
      ],
      "metadata": {
        "id": "FdUZhFGBUv6z"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The initial setup of the learning process\n",
        "print(iterative_process.initialize.type_signature.formatted_representation())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2249028-63a3-4cdd-f884-d43e63b9e125",
        "id": "KNmoEYFdUv61"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "( -> <\n",
            "  global_model_weights=<\n",
            "    trainable=<\n",
            "      float32[5,16],\n",
            "      float32[16],\n",
            "      float32[16,6],\n",
            "      float32[6],\n",
            "      float32[6,1],\n",
            "      float32[1]\n",
            "    >,\n",
            "    non_trainable=<>\n",
            "  >,\n",
            "  distributor=<>,\n",
            "  client_work=<>,\n",
            "  aggregator=<\n",
            "    value_sum_process=<>,\n",
            "    weight_sum_process=<>\n",
            "  >,\n",
            "  finalizer=<\n",
            "    int64,\n",
            "    float32[5,16],\n",
            "    float32[16],\n",
            "    float32[16,6],\n",
            "    float32[6],\n",
            "    float32[6,1],\n",
            "    float32[1]\n",
            "  >\n",
            ">@SERVER)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train"
      ],
      "metadata": {
        "id": "1Q8XzfXlU5q5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the federated model with random clients\n",
        "for round_num in tqdm.tqdm(range(1, 30)):\n",
        "    result = iterative_process.next(state, [f[0] for f in federated_insurance_data])\n",
        "    state = result.state\n",
        "    metrics = result.metrics\n",
        "    for name, value in metrics['client_work']['train'].items():\n",
        "        tf.summary.scalar(name, value, step=round_num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51e1589d-2687-4ccf-c53c-0b6a3ee2bc7a",
        "id": "lEUgryWFU5q6"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:06<00:00,  4.28it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TwFehjaXOGp",
        "outputId": "e9e88877-ee21-4ae6-a800-8da6e8a66e34"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('distributor', ()),\n",
              "             ('client_work',\n",
              "              OrderedDict([('train',\n",
              "                            OrderedDict([('mean_absolute_error', 0.0),\n",
              "                                         ('loss', 0.0),\n",
              "                                         ('num_examples', 0),\n",
              "                                         ('num_batches', 0)]))])),\n",
              "             ('aggregator',\n",
              "              OrderedDict([('mean_value', ()), ('mean_weight', ())])),\n",
              "             ('finalizer', OrderedDict([('update_non_finite', 1)]))])"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.state\n",
        "# all weights are zero\n",
        "# -> nothing is learned "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "573d55df-bb47-4e50-899f-88df781cfcd3",
        "id": "x3opn587U5q8"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LearningAlgorithmState(global_model_weights=ModelWeights(trainable=[array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "      dtype=float32), array([[0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.]], dtype=float32), array([0., 0., 0., 0., 0., 0.], dtype=float32), array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]], dtype=float32), array([0.], dtype=float32)], non_trainable=[]), distributor=(), client_work=(), aggregator=OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())]), finalizer=ListWrapper([0, array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "      dtype=float32), array([[0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.]], dtype=float32), array([0., 0., 0., 0., 0., 0.], dtype=float32), array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]], dtype=float32), array([0.], dtype=float32)]))"
            ]
          },
          "metadata": {},
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate"
      ],
      "metadata": {
        "id": "kWHGNcN-VA98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the test data for model evaluation\n",
        "X_test = pd.concat([f[1][0] for f in federated_insurance_data])\n",
        "y_test = pd.concat([f[1][1] for f in federated_insurance_data])\n",
        "\n",
        "test_sets = [tf.data.Dataset.from_tensor_slices(\n",
        "    (tf.convert_to_tensor(np.expand_dims(el[1][0], axis=0)), \n",
        "    tf.convert_to_tensor(np.expand_dims(el[1][1], axis=0)))) \n",
        "    for el in federated_insurance_data]"
      ],
      "metadata": {
        "id": "1qAVD1haVA9-"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation\n",
        "evaluation = tff.learning.build_federated_evaluation(model_fn_5)\n",
        "# print(evaluation.type_signature.formatted_representation())\n",
        "model_weights = iterative_process.get_model_weights(state)\n",
        "train_metrics = evaluation(model_weights, test_sets)\n",
        "train_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "112fc38e-57c3-486b-e999-aca36868cef5",
        "id": "xHTiYD-nVA9_"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-204-8b7832a90ebf>:2: DeprecationWarning: `tff.learning.build_federated_evaluation` is deprecated, use `tff.learning.algorithms.build_fed_eval` instead.\n",
            "  evaluation = tff.learning.build_federated_evaluation(model_fn_5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('eval',\n",
              "              OrderedDict([('mean_absolute_error', nan),\n",
              "                           ('loss', 0.0),\n",
              "                           ('num_examples', 0),\n",
              "                           ('num_batches', 3)]))])"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model from training results and evaluate\n",
        "model = create_keras_model(input_features = 5)\n",
        "model_weights.assign_weights_to(model)\n",
        "model.compile(\n",
        "    loss=tf.losses.mae,\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    metrics=[\"mae\", 'mean_squared_error']\n",
        ")\n",
        "# The evaluation results, for technical reasons the metrics_names is called afterwards. However, its order fits to the results\n",
        "#print(model.evaluate(X_test, y_test))\n",
        "print(model.metrics_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0087a56f-6cda-4a77-fe7e-8af9046d9e8d",
        "id": "ob4g5OHuVA-A"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    }
  ]
}