{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Olhaau/fl-official-statistics-addon/blob/main/_dev/03_insurance_federated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1N2mtyx2Uxs"
      },
      "source": [
        "# Medical Insurance - a Federated Learning Use Case.\n",
        "\n",
        "This notebook contains Federated Learning.\n",
        "\n",
        "-- **more tba** --"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qdJnO4M7VDO"
      },
      "source": [
        "## Setup\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-28T14:27:44.075055Z",
          "iopub.status.busy": "2023-03-28T14:27:44.075055Z",
          "iopub.status.idle": "2023-03-28T14:27:44.092127Z",
          "shell.execute_reply": "2023-03-28T14:27:44.092127Z",
          "shell.execute_reply.started": "2023-03-28T14:27:44.075055Z"
        },
        "tags": [],
        "id": "urYRSTDKV8Nl"
      },
      "outputs": [],
      "source": [
        "# Is a repo-clone and installs needed (e.g. in colabs)? \n",
        "need_clone_install = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZQgDGzbd3pm"
      },
      "source": [
        "### Pull Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-03-28T11:35:39.951921Z",
          "iopub.status.busy": "2023-03-28T11:35:39.950864Z",
          "iopub.status.idle": "2023-03-28T11:36:02.975338Z",
          "shell.execute_reply": "2023-03-28T11:36:02.974338Z",
          "shell.execute_reply.started": "2023-03-28T11:35:39.951921Z"
        },
        "id": "F5qBP638d0iR",
        "outputId": "fa117f09-6cd7-4fa5-9cd7-49a68233f38d",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fl-official-statistics-addon'...\n",
            "remote: Enumerating objects: 794, done.\u001b[K\n",
            "remote: Counting objects: 100% (430/430), done.\u001b[K\n",
            "remote: Compressing objects: 100% (263/263), done.\u001b[K\n",
            "remote: Total 794 (delta 216), reused 355 (delta 161), pack-reused 364\u001b[K\n",
            "Receiving objects: 100% (794/794), 36.98 MiB | 11.92 MiB/s, done.\n",
            "Resolving deltas: 100% (339/339), done.\n",
            "Updating files: 100% (292/292), done.\n",
            "/content/fl-official-statistics-addon\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "if need_clone_install:\n",
        "    import os\n",
        "    \n",
        "    # rm repo from gdrive\n",
        "    if os.path.exists(\"fl-official-statistics-addon\"):\n",
        "      %rm -r fl-official-statistics-addon\n",
        "\n",
        "    # clone\n",
        "    !git clone https://github.com/Olhaau/fl-official-statistics-addon\n",
        "    %cd fl-official-statistics-addon\n",
        "\n",
        "    # pull (the currenct version of the repo)\n",
        "    !git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d5TMrK67Xxv"
      },
      "source": [
        "### Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UQSYlSd47WaM",
        "outputId": "0d13d4e8-b5ee-4ec8-94bf-d2b75c381c2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 KB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.8/255.8 KB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.0/349.0 KB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.2/120.2 KB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 KB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.6/532.6 KB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.7/126.7 KB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.8/39.8 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 KB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 KB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 KB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pymc 5.1.2 requires cachetools>=4.2.1, but you have cachetools 3.1.1 which is incompatible.\n",
            "orbax 0.1.6 requires jax>=0.4.6, but you have jax 0.3.15 which is incompatible.\n",
            "google-colab 1.0.0 requires portpicker~=1.3.1, but you have portpicker 1.5.2 which is incompatible.\n",
            "flax 0.6.7 requires jax>=0.4.2, but you have jax 0.3.15 which is incompatible.\n",
            "arviz 0.15.1 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "if need_clone_install: \n",
        "  !pip install --quiet nest_asyncio\n",
        "  !pip install --quiet tensorflow_federated\n",
        "  !pip install --quiet tensorflow_addons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUcRlUPV7bZi"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2zMmbNFf7Wc6",
        "outputId": "1d170081-36be-41f3-ca56-39be66df352c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tqdm\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "from tensorflow_addons.metrics import RSquare\n",
        "import tensorflow_addons as tfa\n",
        "import nest_asyncio\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxFNFscq8O74"
      },
      "source": [
        "## Ingest and Split the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "C9zyHqiN9fCo",
        "outputId": "827de64a-7cf5-46c7-dcb4-0934c757e33c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        age  sex       bmi  children  smoker     region      charges  region0  \\\n",
              "0  0.021739  0.0  0.321227       0.0     1.0  southwest  16884.92400      0.0   \n",
              "1  0.000000  1.0  0.479150       0.2     0.0  southeast   1725.55230      0.0   \n",
              "2  0.217391  1.0  0.458434       0.6     0.0  southeast   4449.46200      0.0   \n",
              "3  0.326087  1.0  0.181464       0.0     0.0  northwest  21984.47061      0.0   \n",
              "4  0.304348  1.0  0.347592       0.0     0.0  northwest   3866.85520      0.0   \n",
              "\n",
              "   region1  region2  region3  \n",
              "0      0.0      0.0      1.0  \n",
              "1      0.0      1.0      0.0  \n",
              "2      0.0      1.0      0.0  \n",
              "3      1.0      0.0      0.0  \n",
              "4      1.0      0.0      0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48e750f0-b2eb-4a7a-a4b6-d5e9d3d04bad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "      <th>region0</th>\n",
              "      <th>region1</th>\n",
              "      <th>region2</th>\n",
              "      <th>region3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.021739</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.321227</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.479150</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.217391</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.458434</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.326087</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.181464</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.304348</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.347592</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48e750f0-b2eb-4a7a-a4b6-d5e9d3d04bad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-48e750f0-b2eb-4a7a-a4b6-d5e9d3d04bad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-48e750f0-b2eb-4a7a-a4b6-d5e9d3d04bad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df = pd.read_csv(\"output/data/insurance-clean.csv\", index_col = 0)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Qam6babo7Wgg"
      },
      "outputs": [],
      "source": [
        "NUM_CLIENTS = 4\n",
        "NUM_EPOCHS = 5\n",
        "BATCH_SIZE = 10\n",
        "SHUFFLE_BUFFER = 20\n",
        "PREFETCH_BUFFER = 5\n",
        "NUM_ROUNDS = 150\n",
        "RUN_NAME = f'0,8-3({NUM_ROUNDS})-{NUM_EPOCHS}-epochs-{BATCH_SIZE}-batch-WithRegion/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JTutbOjq8VzQ"
      },
      "outputs": [],
      "source": [
        "syn_samples_per_region = 1000\n",
        "\n",
        "def get_dataset_for_region(dataset, region_index, test_size_per_region=20):\n",
        "    \"\"\"Min-max scale and return data for a single, given region. The scaler must be fitted before.\n",
        "\n",
        "    :param dataset: The dataset to get the regional data from\n",
        "    :type dataset: pandas.DataFrame\n",
        "    :param region_index: The index number of the region to return\n",
        "    :type region_index: int\n",
        "    :param test_size_per_region: The amount of values to separate for testing, default are 20\n",
        "    :type test_size_per_region: int, optional\n",
        "    :return: The dataset specific for the defined region, the test values, the test labels\n",
        "    :rtype: tensorflow.python.data.ops.dataset_ops.PrefetchDataset, tuple of pandas.core.series.Series\n",
        "    \"\"\"\n",
        "    region_ds = dataset[dataset['region'] == region_index]\n",
        "    region_ds = region_ds.drop(columns=['region'])\n",
        "    len = region_ds.shape[0]\n",
        "\n",
        "    # The scaling into [0, 1] is not necessary anymore, it happens when the data loads already\n",
        "    # region_ds[['age', 'bmi', 'children']] = scaler.transform(region_ds[['age', 'bmi', 'children']])\n",
        "\n",
        "    X_test = region_ds.head(test_size_per_region)\n",
        "    y_test = X_test.pop('charges')\n",
        "\n",
        "    X_train = region_ds.tail(len - test_size_per_region)\n",
        "    y_train = X_train.pop('charges')\n",
        "\n",
        "    fed_train_dataset = tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(X_train), tf.convert_to_tensor(y_train)))\n",
        "\n",
        "    return (\n",
        "        fed_train_dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER, seed=1).batch(BATCH_SIZE).prefetch(PREFETCH_BUFFER),\n",
        "        (X_test, y_test)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8FEwLlGv8eq3"
      },
      "outputs": [],
      "source": [
        "# Create test and train sets and put them into random_client_ds, use four clients which are independent of the region\n",
        "def get_dataset_random_region(dataset, num_clients=4, test_size_per_region=20):\n",
        "    \"\"\"Creates a list with client datasets independent of the region.\n",
        "\n",
        "    :param dataset: The dataset to get the regional data from\n",
        "    :type dataset: pandas.DataFrame\n",
        "    :param num_clients: the number of clients create (equal big datasets per client), default value is 4 clients\n",
        "    :type num_clients: int, optional\n",
        "    :param test_size_per_region: The amount of values to separate for testing, default are 20\n",
        "    :type test_size_per_region: int, optional\n",
        "    :return: List of the prepared dataset with one entry per region, the test values and labels for each region\n",
        "    :rtype: List of (tensorflow.python.data.ops.dataset_ops.PrefetchDataset, tuple of pandas.core.series.Series)\"\"\"\n",
        "    size_of_client_ds = int(dataset.shape[0] / num_clients)\n",
        "\n",
        "    dataset_to_split = dataset.copy()\n",
        "    dataset_to_split.pop(\"region\")\n",
        "    random_client_ds = []\n",
        "    for i in range(num_clients):\n",
        "        sampled = dataset_to_split.sample(n=size_of_client_ds)\n",
        "        dataset_to_split.drop(sampled.index)\n",
        "\n",
        "        X_test = sampled.head(test_size_per_region)\n",
        "        y_test = X_test.pop('charges')\n",
        "\n",
        "        X_train = sampled.tail(size_of_client_ds - test_size_per_region)\n",
        "        y_train = X_train.pop('charges')\n",
        "\n",
        "        fed_train_dataset = tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(X_train), tf.convert_to_tensor(y_train)))\n",
        "\n",
        "        train_set = fed_train_dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER, seed=1).batch(BATCH_SIZE).prefetch(PREFETCH_BUFFER)\n",
        "        test_set = (X_test, y_test)\n",
        "\n",
        "        random_client_ds.append((train_set, test_set))\n",
        "\n",
        "    return random_client_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dirvrz6Y9ARK",
        "outputId": "54cd90e6-62e3-4a95-a0d1-85c35c886b6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 5), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>,\n",
              "  (Empty DataFrame\n",
              "   Columns: [age, sex, bmi, children, smoker]\n",
              "   Index: [], Series([], Name: charges, dtype: float64))),\n",
              " (<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 5), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>,\n",
              "  (Empty DataFrame\n",
              "   Columns: [age, sex, bmi, children, smoker]\n",
              "   Index: [], Series([], Name: charges, dtype: float64))),\n",
              " (<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 5), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>,\n",
              "  (Empty DataFrame\n",
              "   Columns: [age, sex, bmi, children, smoker]\n",
              "   Index: [], Series([], Name: charges, dtype: float64)))]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Training data for clients with regional data (each client one region)\n",
        "test_size_per_region = 20\n",
        "regions = ['region0', 'region1', 'region2', 'region3']\n",
        "\n",
        "federated_insurance_data = [\n",
        "    get_dataset_for_region(df.drop(regions, axis=1), i, test_size_per_region=test_size_per_region)\n",
        "    for i in range(NUM_CLIENTS-1)]\n",
        "federated_insurance_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mX6HRriR9Cil"
      },
      "outputs": [],
      "source": [
        "# Training data for clients with regional independent data\n",
        "random_client_ds = get_dataset_random_region(df, num_clients=NUM_CLIENTS, test_size_per_region=test_size_per_region)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiNQ6m66A7sa"
      },
      "source": [
        "### Code Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRbSvR-Q9058",
        "outputId": "74ef265b-1052-46b0-e3e2-3b5388426d63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "splitted datasets: 3\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "print(\"splitted datasets: {}\".format(len(federated_insurance_data)))\n",
        "print(\"------------------------------\")\n",
        "# Q: why range(NUM_CLIENTS-1) and, thus, only 3 clients?\n",
        "\n",
        "# Q: how to output? -> does not work or nothing in it?\n",
        "# -> i think its empty\n",
        "list(federated_insurance_data[0][0].as_numpy_iterator())[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJY8_tVdCXrz"
      },
      "source": [
        "#### Show Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFohPc1rAqVw",
        "outputId": "1f9ace80-703e-43a8-e4f2-3fa458644107"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TensorSliceDataset element_spec=(TensorSpec(shape=(4,), dtype=tf.float64, name=None), TensorSpec(shape=(), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Create a Tensor Object\n",
        "X_train = df.iloc[:,0:4]\n",
        "y_train = df['charges']\n",
        "df2 = tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(X_train), tf.convert_to_tensor(y_train)))\n",
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpW57hM4DOBI",
        "outputId": "82870ca0-0260-4c16-ce9f-be632b2ca3b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([0.02173913, 0.        , 0.3212268 , 0.        ]), 16884.924),\n",
              " (array([0.        , 1.        , 0.47914985, 0.2       ]), 1725.5523),\n",
              " (array([0.2173913 , 1.        , 0.45843422, 0.6       ]), 4449.462),\n",
              " (array([0.32608696, 1.        , 0.18146355, 0.        ]), 21984.47061),\n",
              " (array([0.30434783, 1.        , 0.34759214, 0.        ]), 3866.8552),\n",
              " (array([0.2826087 , 0.        , 0.26311542, 0.        ]), 3756.6216),\n",
              " (array([0.60869565, 0.        , 0.47027172, 0.2       ]), 8240.5896),\n",
              " (array([0.41304348, 0.        , 0.31692225, 0.6       ]), 7281.5056),\n",
              " (array([0.41304348, 1.        , 0.37315039, 0.4       ]), 6406.4107),\n",
              " (array([0.91304348, 0.        , 0.26580576, 0.        ]), 28923.13692)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Show Tensor Object\n",
        "# S. https://stackoverflow.com/questions/62436302/extract-target-from-tensorflow-prefetchdataset\n",
        "list(df2.as_numpy_iterator())[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PvPyDQL8iXm"
      },
      "source": [
        "## Model Builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9Csom8dD8hRK"
      },
      "outputs": [],
      "source": [
        "def create_keras_model(\n",
        "    input_features = 9,\n",
        "    initializer = 'zeros',\n",
        "    units = [16,6,1],\n",
        "    activation = None\n",
        "    ):\n",
        "    \"\"\"Create neural network for given number of input features)\n",
        "\n",
        "    :param input_features: The dimension of the first layer with represents the amount of features used\n",
        "    :type input_features: int, optional\n",
        "    :return: Created but not compiled model\n",
        "    :rtype: keras.Model\n",
        "    \"\"\"\n",
        "    return tf.keras.models.Sequential([\n",
        "        # without region: tf.keras.layers.InputLayer(input_shape=(5,)),\n",
        "        tf.keras.layers.InputLayer(input_shape=(input_features,)),\n",
        "        tf.keras.layers.Dense(units[0], kernel_initializer=initializer, activation = activation\n",
        "                              ),\n",
        "        tf.keras.layers.Dense(units[1], kernel_initializer=initializer, activation = activation\n",
        "                              ),\n",
        "        tf.keras.layers.Dense(units[2], kernel_initializer=initializer)\n",
        "    ])\n",
        "\n",
        "\n",
        "# A helper function for federated learning\n",
        "def model_fn(    \n",
        "    input_features = 9,\n",
        "    initializer = 'zeros',\n",
        "    units = [16,6,1],\n",
        "    activation = None):\n",
        "    \"\"\"A function for TFF to create a local model during federated learning and return it as the correct type.\n",
        "    This model uses 9 input features i.e. the regions are part of the features.\n",
        "\n",
        "    :return: The LSTM model to be used as federated models\n",
        "    :rtype: tff.learning.Model\n",
        "    \"\"\"\n",
        "    # We _must_ create a new model here, and _not_ capture it from an external\n",
        "    # scope. TFF will call this within different graph contexts.\n",
        "    keras_model = create_keras_model(\n",
        "            input_features = input_features,\n",
        "            initializer = initializer,\n",
        "            activation = activation,\n",
        "            units = units\n",
        "    )\n",
        "    return tff.learning.models.from_keras_model(\n",
        "        keras_model,\n",
        "        # without region: \n",
        "        #input_spec = federated_insurance_data[0][0].element_spec,\n",
        "        input_spec = random_client_ds[0][0].element_spec,\n",
        "        loss = tf.keras.losses.MeanAbsoluteError(),\n",
        "        metrics = [tf.keras.metrics.MeanAbsoluteError()\n",
        "        #,tfa.metrics.RSquare()\n",
        "        ]\n",
        "    )\n",
        "\n",
        "# Helper functions for different features as input\n",
        "def model_fn_5():\n",
        "    return model_fn(5)\n",
        "\n",
        "def model_fn_5_mod():\n",
        "  return model_fn(5, initializer = 'glorot_uniform', activation = 'relu')\n",
        "\n",
        "def model_fn_9():\n",
        "  return model_fn(9)\n",
        "\n",
        "def model_fn_9_mod():\n",
        "  return model_fn(9, initializer = 'glorot_uniform', activation = 'relu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "in t\n",
        "\n",
        "tff.learning.models.from_keras_model"
      ],
      "metadata": {
        "id": "sKKYrF7KXp47",
        "outputId": "1fafa3da-2589-430e-9951-fb3b0e774567",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function tensorflow_federated.python.learning.models.keras_utils.from_keras_model(keras_model: keras.engine.training.Model, loss: Union[keras.losses.Loss, list[keras.losses.Loss]], input_spec, loss_weights: Optional[list[float]] = None, metrics: Union[list[keras.metrics.base_metric.Metric], list[collections.abc.Callable[[], keras.metrics.base_metric.Metric]], NoneType] = None) -> tensorflow_federated.python.learning.models.variable.VariableModel>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Sc8xDdk2RTp"
      },
      "source": [
        "## Federated Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GGvMq3ATosV"
      },
      "source": [
        "### Original Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgodbIMsH2b9"
      },
      "source": [
        "#### Create Learning Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "K3k21nSQ9P-D"
      },
      "outputs": [],
      "source": [
        "# Create iterative learning process which will perform the federated learning\n",
        "iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn_9,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.8),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBMUBG1tHFfC"
      },
      "outputs": [],
      "source": [
        "# The initial setup of the learning process\n",
        "print(iterative_process.initialize.type_signature.formatted_representation())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A-Lx1oGH9Jy"
      },
      "source": [
        "#### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuAoyOYNbyr5"
      },
      "outputs": [],
      "source": [
        "state = iterative_process.initialize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSqO7EPIHQXJ"
      },
      "outputs": [],
      "source": [
        "# Train the federated model with random clients\n",
        "for round_num in tqdm.tqdm(range(1, NUM_ROUNDS)):\n",
        "    result = iterative_process.next(state, [f[0] for f in random_client_ds])\n",
        "    state = result.state\n",
        "    metrics = result.metrics\n",
        "    for name, value in metrics['client_work']['train'].items():\n",
        "        tf.summary.scalar(name, value, step=round_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03Kpx2vpWhQY"
      },
      "outputs": [],
      "source": [
        "result.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhYfnkG4T1qf"
      },
      "outputs": [],
      "source": [
        "result.state\n",
        "# all weights are zero\n",
        "# -> nothing is learned "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqkadG5nH_KU"
      },
      "source": [
        "#### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwZd8b3FHjuh"
      },
      "outputs": [],
      "source": [
        "# Create the test data for model evaluation\n",
        "X_test = pd.concat([f[1][0] for f in random_client_ds])\n",
        "y_test = pd.concat([f[1][1] for f in random_client_ds])\n",
        "\n",
        "test_sets = [tf.data.Dataset.from_tensor_slices(\n",
        "    (tf.convert_to_tensor(np.expand_dims(el[1][0], axis=0)), \n",
        "    tf.convert_to_tensor(np.expand_dims(el[1][1], axis=0)))) \n",
        "    for el in random_client_ds]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wl-0NiBSJDuO"
      },
      "outputs": [],
      "source": [
        "# Model evaluation\n",
        "evaluation = tff.learning.build_federated_evaluation(model_fn_9)\n",
        "# print(evaluation.type_signature.formatted_representation())\n",
        "model_weights = iterative_process.get_model_weights(state)\n",
        "train_metrics = evaluation(model_weights, test_sets)\n",
        "train_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHtfuogKJe6z"
      },
      "outputs": [],
      "source": [
        "# Create model from training results and evaluate\n",
        "model = create_keras_model(input_features = 9)\n",
        "model_weights.assign_weights_to(model)\n",
        "model.compile(\n",
        "    loss=tf.losses.mae,\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    metrics=[\"mae\", 'mean_squared_error']\n",
        ")\n",
        "# The evaluation results, for technical reasons the metrics_names is called afterwards. However, its order fits to the results\n",
        "print(model.evaluate(X_test, y_test))\n",
        "print(model.metrics_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-5ZQ6AyUpyX"
      },
      "source": [
        "### Test New Learner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLjpPo1sU3A2"
      },
      "source": [
        "#### Create Learning Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdUZhFGBUv6z"
      },
      "outputs": [],
      "source": [
        "# Create iterative learning process which will perform the federated learning\n",
        "iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn_9_mod,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.01),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=.05))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNmoEYFdUv61"
      },
      "outputs": [],
      "source": [
        "# The initial setup of the learning process\n",
        "print(iterative_process.initialize.type_signature.formatted_representation())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q8XzfXlU5q5"
      },
      "source": [
        "#### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROyd0BlXb2xr"
      },
      "outputs": [],
      "source": [
        "state = iterative_process.initialize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEUgryWFU5q6"
      },
      "outputs": [],
      "source": [
        "# Train the federated model with random clients\n",
        "for round_num in tqdm.tqdm(range(1, NUM_ROUNDS)):\n",
        "    result = iterative_process.next(state, [f[0] for f in random_client_ds])\n",
        "    state = result.state\n",
        "    metrics = result.metrics\n",
        "    for name, value in metrics['client_work']['train'].items():\n",
        "        tf.summary.scalar(name, value, step=round_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TwFehjaXOGp"
      },
      "outputs": [],
      "source": [
        "result.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3opn587U5q8"
      },
      "outputs": [],
      "source": [
        "result.state\n",
        "# all weights are zero\n",
        "# -> nothing is learned "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWHGNcN-VA98"
      },
      "source": [
        "#### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qAVD1haVA9-"
      },
      "outputs": [],
      "source": [
        "# Create the test data for model evaluation\n",
        "X_test = pd.concat([f[1][0] for f in federated_insurance_data])\n",
        "y_test = pd.concat([f[1][1] for f in federated_insurance_data])\n",
        "\n",
        "test_sets = [tf.data.Dataset.from_tensor_slices(\n",
        "    (tf.convert_to_tensor(np.expand_dims(el[1][0], axis=0)), \n",
        "    tf.convert_to_tensor(np.expand_dims(el[1][1], axis=0)))) \n",
        "    for el in federated_insurance_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHTiYD-nVA9_"
      },
      "outputs": [],
      "source": [
        "# Model evaluation\n",
        "evaluation = tff.learning.build_federated_evaluation(model_fn_5_mod)\n",
        "# print(evaluation.type_signature.formatted_representation())\n",
        "model_weights = iterative_process.get_model_weights(state)\n",
        "train_metrics = evaluation(model_weights, test_sets)\n",
        "train_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NKLXp9aiDqA"
      },
      "outputs": [],
      "source": [
        "r2scr = RSquare\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ob4g5OHuVA-A"
      },
      "outputs": [],
      "source": [
        "# Create model from training results and evaluate\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "model = create_keras_model(input_features = 9)\n",
        "model_weights.assign_weights_to(model)\n",
        "model.compile(\n",
        "    loss=tf.losses.mae,\n",
        "    optimizer=tf.optimizers.SGD(),\n",
        "    metrics=[\"mae\", 'mean_squared_error'#, r2_score\n",
        "             ]\n",
        ")\n",
        "\n",
        "# The evaluation results, for technical reasons the metrics_names is called afterwards. However, its order fits to the results\n",
        "print(model.evaluate(X_test, y_test))\n",
        "print(model.metrics_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_9XHZx0XddY"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI5W1ESJXe4z"
      },
      "source": [
        "- the original repo uses a totally different model as in centralized learning.\n",
        "  - linear\n",
        "  - no learning by zero initializer\n",
        "- new learner cuts mae ~66%\n",
        "- how to calculate RSquare?\n",
        "- error: no learning occurs (for clients). Empty?\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}