{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Olhaau/fl-official-statistics-addon/blob/main/_dev/__review2_99d_insurance_federated_wrapup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWsCh8Yxci_O"
      },
      "source": [
        "# Federated Insurance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia10zJ2Kci_Q"
      },
      "source": [
        "## Prerequisites\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv7MsvZEci_R"
      },
      "source": [
        "### Libraries\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZJRN3dyci_R",
        "outputId": "1411282b-3389-4244-cfb5-59645d854400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COLAB? True\n",
            "Cloning into 'fl-official-statistics-addon'...\n",
            "remote: Enumerating objects: 7070, done.\u001b[K\n",
            "remote: Counting objects: 100% (4362/4362), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1146/1146), done.\u001b[K\n",
            "remote: Total 7070 (delta 1124), reused 4313 (delta 1090), pack-reused 2708\u001b[K\n",
            "Receiving objects: 100% (7070/7070), 88.79 MiB | 14.65 MiB/s, done.\n",
            "Resolving deltas: 100% (2531/2531), done.\n",
            "Updating files: 100% (10100/10100), done.\n",
            "/content/fl-official-statistics-addon\n",
            "Already up to date.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.6/142.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m558.5/558.5 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.8/255.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.0/349.0 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.7/126.7 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.6/532.6 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for farmhashpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Setup colab if needed\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "print(\"COLAB? {}\".format(IN_COLAB))\n",
        "\n",
        "if IN_COLAB:\n",
        "    import os\n",
        "\n",
        "    # rm repo from gdrive\n",
        "    if os.path.exists(\"fl-official-statistics-addon\"):\n",
        "      %rm -r fl-official-statistics-addon\n",
        "\n",
        "    # clone\n",
        "    !git clone https://github.com/Olhaau/fl-official-statistics-addon\n",
        "    %cd fl-official-statistics-addon\n",
        "\n",
        "    # pull (the currenct version of the repo)\n",
        "    !git pull\n",
        "\n",
        "    !pip install -q tensorflow-federated==0.56.0\n",
        "    # or possibly !pip install -r requirements.txt\n",
        "\n",
        "    os.chdir(\"_dev\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmSZBh21ci_S"
      },
      "outputs": [],
      "source": [
        "!python --version\n",
        "# tested 3.9.* or 3.10.*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2YnElSwci_T"
      },
      "outputs": [],
      "source": [
        "# show library versions\n",
        "# =========================\n",
        "!pip list | grep tensorflow\n",
        "# tensorflow                    2.12.0\n",
        "# tensorflow-federated          0.56.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VY8cX-yZci_U"
      },
      "outputs": [],
      "source": [
        "# suppress tf debug logging\n",
        "# =========================\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "#0 = all messages are logged (default behavior)\n",
        "#1 = INFO messages are not printed\n",
        "#2 = INFO and WARNING messages are not printed\n",
        "#3 = INFO, WARNING, and ERROR messages are not printed\n",
        "\n",
        "# S. https://stackoverflow.com/questions/35911252/disable-tensorflow-debugging-information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4Drwowyci_U"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "# =======\n",
        "\n",
        "# basics: data, calculations and plots\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# tensorflow (federated) and keras\n",
        "import tensorflow_federated as tff\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import CSVLogger\n",
        "\n",
        "# model selection\n",
        "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
        "\n",
        "# statusbar for loops\n",
        "import tqdm\n",
        "\n",
        "# helper functions\n",
        "from FLutils import (\n",
        "    load_df,               # load data\n",
        "    create_keras_model,    # construct a deep neural network (keras)\n",
        "    model_fn,              # convert keras model to tff.learning.models\n",
        "    prep_fed_train,        # convert training data to tensors for learning with tensorflow\n",
        "    prep_fed_test,         # convert test data to tensors for testing with tensorflow (other format than training data)\n",
        "    train_model,           # train a keras model\n",
        "    train_fed              # train a keras model federated with distributed data\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhILV_JoYkJV"
      },
      "outputs": [],
      "source": [
        "# output path for logging\n",
        "# =======================\n",
        "\n",
        "out_path = '../output/experiments/10_review'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfbB-i3Qci_W"
      },
      "source": [
        "### Data preperation\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziROoGFxYkJX"
      },
      "source": [
        "See [pycaret tutorial about the data set](https://nbviewer.org/github/pycaret/pycaret/blob/master/tutorials/Tutorial%20-%20Regression.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGsvLfT0ci_W"
      },
      "outputs": [],
      "source": [
        "# ingest data\n",
        "# ===========\n",
        "\n",
        "df_paths = [\n",
        "    '../output/data/insurance-clean.csv',\n",
        "    \"https://raw.githubusercontent.com/Olhaau/fl-official-statistics-addon/main/output/data/insurance-clean.csv\"\n",
        "]\n",
        "\n",
        "# rem.: even easier with pycaret:\n",
        "#from pycaret.datasets import get_data\n",
        "#df = get_data('insurance')\n",
        "\n",
        "df = load_df(df_paths)\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UF11-40xYkJY"
      },
      "outputs": [],
      "source": [
        "# shape of the data set\n",
        "# =====================\n",
        "\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTWLHmEqci_X"
      },
      "outputs": [],
      "source": [
        "# select features, target (first column) and clients\n",
        "# ==================================================\n",
        "\n",
        "# features for centralized learning\n",
        "features = ['age', 'sex', 'bmi', 'children', 'smoker'\n",
        "            , 'region0', 'region1', 'region2', 'region3']\n",
        "\n",
        "target = 'charges'\n",
        "\n",
        "# features for federated learning\n",
        "features_fed = features[:5]\n",
        "\n",
        "# clients for data splits\n",
        "clients = df.region.unique()\n",
        "\n",
        "# show target + features in the data\n",
        "df.loc[:, [target] + features].head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUjlgi3_ci_X"
      },
      "source": [
        "### Budget\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnEwK5OiYkJZ"
      },
      "source": [
        "#### Evaluation\n",
        "\n",
        "For fast explorations the budget can be reduced significantly. Recommended are\n",
        "\n",
        "- `nreps = 1`: only one rep is required\n",
        "- `nfolds` > 3: at least 3 cross validation folds to have enough training data\n",
        "- `n_epochs`, `n_epochs_fed`, `n_rounds_fed`: can for technical test be very small (~ 10). For methodological test at least 50-100 iterations are needed to show the resulting performance, e.g. `n_epochs` > 60 or `n_epochs_fed` + `n_rounds_fed` > 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbpM29mRci_Y"
      },
      "outputs": [],
      "source": [
        "# create evaluation splits\n",
        "# ========================\n",
        "\n",
        "nreps, nfolds = 1, 3\n",
        "evaluation = RepeatedStratifiedKFold(n_splits = nfolds, n_repeats = nreps, random_state = 42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jzJRfuvci_Y"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRGyiTwNci_Y"
      },
      "outputs": [],
      "source": [
        "# training budget\n",
        "# ===============\n",
        "\n",
        "n_epochs     = 100 # epochs (centralized training)\n",
        "n_epochs_fed =  50 # epochs for each client in one server iteration (federated training)\n",
        "n_rounds_fed =  50 # federated training rounds including distribution to the clients and aggregation of the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WputHxfvci_Z"
      },
      "source": [
        "### Model\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqpIq7xMci_Z"
      },
      "outputs": [],
      "source": [
        "# define model architecture\n",
        "# =========================\n",
        "\n",
        "def keras_blueprint(compile = False, nfeatures = len(features_fed)):\n",
        "    if nfeatures == None: nfeatures = len(features)\n",
        "\n",
        "    return create_keras_model(\n",
        "        nfeatures = nfeatures,\n",
        "        units = [40, 40, 20],\n",
        "        activations = ['relu'] * 3,\n",
        "        compile = compile)\n",
        "\n",
        "# Note 1: we do not compile the model yet. The loss, metrics, and optimizers are introduced later.\n",
        "#   S. https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification#creating_a_model_with_keras\n",
        "# Note 2: this function has to generate a new instance of a keras_model\n",
        "#   to be useable for generating a federated learning process\n",
        "# Note 3: loss = mae -> overfitting?\n",
        "\n",
        "# show the model specifics\n",
        "keras_blueprint().summary()\n",
        "keras_blueprint(compile=True).get_compile_config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLEGXjUHYkJa"
      },
      "source": [
        "### Federated Process\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPhVvTDLYkJa"
      },
      "source": [
        "In [TensorFlow Federated](https://www.tensorflow.org/federated), the default server optimizer function is [tf.keras.optimizers.SGD](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/experimental/SGD) with a learning rate of 1.0, which corresponds to adding the model delta to the current server model. This recovers the original FedAvg algorithm in [McMahan et al., 2017](https://arxiv.org/abs/1602.05629) (cf. [tff.learning.algorithms.build_weighted_fed_avg](https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms/build_weighted_fed_avg)).\n",
        "\n",
        "\n",
        "We modified the server optimizer to use `Adam` with a learning rate of `0.05`. led to increased stability in our training performance. In the cross-device setting, as demonstrated by [Reddi et al., 2021](https://arxiv.org/abs/2003.00295), adaptive optimizers outperform non-adaptive ones, particularly when dealing with client drift, aka inhomogenous clients.     \n",
        "\n",
        "![](https://github.com/Olhaau/fl-official-statistics-addon/blob/main/doc/reddi20-algo2.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn_8IcOIYkJb"
      },
      "source": [
        "Technically, the federated training process is constructed from a keras model in the function `train_fed`. See `help(train_fed)`. We use the following process:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fp3l68L0YkJb"
      },
      "outputs": [],
      "source": [
        "# show the federated learning process\n",
        "# ===================================\n",
        "tff_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "\tmodel_fn(\n",
        "\t\tkeras_creator = keras_blueprint,\n",
        "\t\tloss = tf.losses.MeanSquaredError()\n",
        "\t),\n",
        "\tclient_optimizer_fn = lambda: tf.optimizers.Adam(learning_rate = .05),\n",
        "\tserver_optimizer_fn = lambda: tf.optimizers.Adam(learning_rate = .05)\n",
        " )\n",
        "\n",
        "print(tff_process.initialize.type_signature.formatted_representation())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9T5uL8Yci_Z"
      },
      "source": [
        "## Federated Learning\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mnu5RlYci_a"
      },
      "outputs": [],
      "source": [
        "# experiment logging\n",
        "# ==================\n",
        "\n",
        "experiment_name = '06_federated_fix'\n",
        "\n",
        "experiment_path = out_path + \"/\" + experiment_name + \"/\"\n",
        "if not os.path.exists(experiment_path + 'logs'): os.makedirs(experiment_path + 'logs')\n",
        "if not os.path.exists(experiment_path + 'models'): os.makedirs(experiment_path + 'models')\n",
        "if not os.path.exists(experiment_path + 'results'): os.makedirs(experiment_path + 'results')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiAUC-sDci_a"
      },
      "source": [
        "### FED Train\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6BePRvFci_a"
      },
      "outputs": [],
      "source": [
        "# compute train\n",
        "# =============\n",
        "\n",
        "results_fed = []\n",
        "\n",
        "eval_ind = 0 #nfolds*7#0\n",
        "for train, test in tqdm.tqdm(list(evaluation.split(df, df.region))[:]):\n",
        "\n",
        "    # Logging\n",
        "    rep  = int(eval_ind / nfolds)\n",
        "    fold = int(eval_ind % nfolds)\n",
        "    eval_ind += 1\n",
        "    id = \"r\" + str(rep) + \"f\" + str(fold)\n",
        "    #print('======= rep %s - fold %s  =======' % (rep, fold))\n",
        "\n",
        "\n",
        "    # distribute train (and eval) data over the client and prep tensors.\n",
        "    train_data_fed = []\n",
        "    eval_data_fed  = []\n",
        "    for client in clients:\n",
        "        outer_train_data_client = df[(df.index.isin(train)) & (df.region == client)]\n",
        "        train_data_client, eval_data_client = train_test_split(outer_train_data_client, test_size = 0.1, random_state = 42)\n",
        "\n",
        "        train_data_fed.append(\n",
        "            prep_fed_train(train_data_client[features_fed], train_data_client[target]))\n",
        "        eval_data_fed.append(\n",
        "            prep_fed_test(eval_data_client[features_fed], eval_data_client[target]))\n",
        "\n",
        "    # train\n",
        "    #with tf.device('/device:gpu:0'): # possibly needed for colab\n",
        "    result =  train_fed(\n",
        "        model = model_fn(\n",
        "            keras_creator = keras_blueprint,\n",
        "            loss = tf.losses.MeanSquaredError()\n",
        "        ),\n",
        "        train_data = train_data_fed,\n",
        "        eval_data  = eval_data_fed,\n",
        "        NUM_ROUNDS = n_rounds_fed,\n",
        "        NUM_EPOCHS = n_epochs_fed,\n",
        "        client_optimizer = lambda: tf.optimizers.Adam(learning_rate = .05),\n",
        "        server_optimizer = lambda: tf.optimizers.Adam(learning_rate = .05),\n",
        "        BATCH_SIZE = 128,\n",
        "        SHUFFLE_BUFFER = 20,\n",
        "        PREFETCH_BUFFER = 5,\n",
        "        SEED = 42,\n",
        "        verbose = False\n",
        "    )\n",
        "\n",
        "    # save history\n",
        "    pd.DataFrame(result['history']).to_csv(experiment_path + \"logs/\" + id + '_log.csv', sep = \";\")\n",
        "\n",
        "    # save model\n",
        "    model = keras_blueprint()\n",
        "    model_weights = result['process'].get_model_weights(result['state'])\n",
        "    model_weights.assign_weights_to(model)\n",
        "    model.save_weights(experiment_path + \"models/\" + id + '_weights.h5')\n",
        "\n",
        "    # Note: load with e.g.\n",
        "    #   model = keras_blueprint(compile = True)\n",
        "    #   model.load_weights(experiment_path + 'models/r0f0_weights.h5')\n",
        "    #   model.weights\n",
        "\n",
        "    results_fed.append(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNwY1d8kci_b"
      },
      "outputs": [],
      "source": [
        "# show train result\n",
        "# =======================\n",
        "\n",
        "table = pd.DataFrame([res['history'][-1] for res in results_fed])\n",
        "table.to_csv(experiment_path + \"results/performance_train.csv\", sep = \";\")\n",
        "table.describe().to_csv(experiment_path + \"results/performance_train_overview.csv\", sep = \";\")\n",
        "table.describe().round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jg99uHBUci_b"
      },
      "outputs": [],
      "source": [
        "# plot train result (MAE)\n",
        "# =======================\n",
        "\n",
        "y = np.array([[hist['mean_absolute_error'] for hist in res['history']] for res in results_fed]).transpose()\n",
        "yval = np.array([[hist['val_mean_absolute_error'] for hist in res['history']] for res in results_fed]).transpose()\n",
        "\n",
        "\n",
        "xran = range(1,y.shape[0] + 1)\n",
        "plt.plot(xran, y, color = 'blue', alpha = .2)\n",
        "plt.plot(xran, np.quantile(y,.5, axis = 1), label = 'training', color = 'blue')\n",
        "plt.plot(xran, yval, color = 'orange', alpha = .2)\n",
        "plt.plot(xran, np.quantile(yval,.5, axis = 1), label = 'evaluation', color = 'orange')\n",
        "plt.xlabel(\"Rounds\")\n",
        "plt.ylabel(\"Mean Absolute Error\")\n",
        "plt.suptitle('Federated Insurance', fontsize=18)\n",
        "plt.title('federated training performance')\n",
        "plt.legend()\n",
        "plt.savefig(experiment_path + 'results/training_performance_mae.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMstkvt5ci_b"
      },
      "outputs": [],
      "source": [
        "# plot train result (MSE)\n",
        "# =======================\n",
        "\n",
        "y = np.array([[hist['mean_squared_error'] for hist in res['history']] for res in results_fed]).transpose()\n",
        "yval = np.array([[hist['val_mean_squared_error'] for hist in res['history']] for res in results_fed]).transpose()\n",
        "\n",
        "\n",
        "xran = range(1,y.shape[0] + 1)\n",
        "plt.plot(xran, y, color = 'blue', alpha = .2)\n",
        "plt.plot(xran, np.quantile(y,.5, axis = 1), label = 'training', color = 'blue')\n",
        "plt.plot(xran, yval, color = 'orange', alpha = .2)\n",
        "plt.plot(xran, np.quantile(yval,.5, axis = 1), label = 'evaluation', color = 'orange')\n",
        "plt.xlabel(\"Rounds\")\n",
        "plt.ylabel(\"Mean Squared Error\")\n",
        "plt.suptitle('Federated Insurance', fontsize=18)\n",
        "plt.title('federated training performance')\n",
        "plt.legend()\n",
        "plt.savefig(experiment_path + 'results/training_performance_mse.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3Lv2KIoci_c"
      },
      "source": [
        "### FED Test\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVgwdsNnci_c"
      },
      "outputs": [],
      "source": [
        "# calculate test\n",
        "# ==============\n",
        "\n",
        "results_fed_test = []\n",
        "\n",
        "model = keras_blueprint(compile = True)\n",
        "\n",
        "i = 0\n",
        "for train, test in tqdm.tqdm(list(evaluation.split(df, df.region))):\n",
        "    data_test = df.loc[test]\n",
        "    X_test, y_test = data_test[features_fed], data_test[target]\n",
        "\n",
        "    # calculate test performance\n",
        "    model_weights = results_fed[i]['process'].get_model_weights(results_fed[i]['state'])\n",
        "    i += 1\n",
        "    model_weights.assign_weights_to(model)\n",
        "\n",
        "    perf_test = model.evaluate(X_test, y_test, verbose = 0)\n",
        "    perf_test = dict(zip(model.metrics_names, perf_test))\n",
        "\n",
        "    results_fed_test.append(perf_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxBkKlRUci_c"
      },
      "outputs": [],
      "source": [
        "# show test results\n",
        "# =================\n",
        "\n",
        "table2 = pd.DataFrame(results_fed_test)\n",
        "table2 = table2.set_axis(['test_'+ col for col in table2.columns], axis = 1)\n",
        "\n",
        "table2.to_csv(experiment_path + \"results/performance_test.csv\", sep = \";\")\n",
        "table2.describe()[1:].to_csv(experiment_path + \"results/performance_test_overview.csv\", sep = \";\")\n",
        "table_all_fed = pd.concat([table, table2], axis = 1)\n",
        "table_all_fed.describe()[1:].to_csv(experiment_path + \"results/performance_overview.csv\", sep = \";\")\n",
        "table_all_fed.to_csv(experiment_path + \"results/performance.csv\", sep = \";\")\n",
        "\n",
        "table_all_fed.describe()[1:].transpose().round(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zpXBqiDci_c"
      },
      "source": [
        "## Centralized DNN\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuCFFloxci_d"
      },
      "source": [
        "### Setup\n",
        "---\n",
        "\n",
        "Using 9 Features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4i9OIizci_d"
      },
      "outputs": [],
      "source": [
        "# experiment logging\n",
        "# =============\n",
        "\n",
        "experiment_name = '07_central_fix'\n",
        "\n",
        "experiment_path = out_path + \"/\" + experiment_name + \"/\"\n",
        "if not os.path.exists(experiment_path + 'logs'): os.makedirs(experiment_path + 'logs')\n",
        "if not os.path.exists(experiment_path + 'models'): os.makedirs(experiment_path + 'models')\n",
        "if not os.path.exists(experiment_path + 'results'): os.makedirs(experiment_path + 'results')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgLXPiCZci_d"
      },
      "source": [
        "### CTR Train\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eqXyhngci_d"
      },
      "outputs": [],
      "source": [
        "# calculate training\n",
        "# ==================\n",
        "\n",
        "results_ctr = []\n",
        "\n",
        "eval_ind = 0\n",
        "for train, test in tqdm.tqdm(list(evaluation.split(df, df.region))):\n",
        "\n",
        "    # Logging\n",
        "    rep  = int(eval_ind / nfolds)\n",
        "    fold = int(eval_ind % nfolds)\n",
        "    eval_ind += 1\n",
        "    id = \"r\" + str(rep) + \"f\" + str(fold)\n",
        "    #print('======= rep %s - fold %s  =======' % (rep, fold))\n",
        "\n",
        "\n",
        "    data_train = df.loc[train]\n",
        "    X_train, y_train = data_train[features], data_train[target]\n",
        "\n",
        "    model = keras_blueprint(nfeatures = len(features), compile = True)\n",
        "\n",
        "    result = train_model(\n",
        "        model, X_train, y_train,\n",
        "        epochs = n_epochs,\n",
        "        #output_msr = \"r2_score\",\n",
        "        callbacks = [CSVLogger(experiment_path + \"logs/\" + id + '_log.csv'  , separator =\";\")],\n",
        "        seed = 42,\n",
        "        verbose = False\n",
        "    )\n",
        "    model.save_weights(experiment_path + \"models/\" + id + '_weights.h5')\n",
        "\n",
        "    results_ctr.append(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aR46gZFci_e"
      },
      "outputs": [],
      "source": [
        "# show train results\n",
        "# ==================\n",
        "\n",
        "table = pd.DataFrame(\n",
        "    [{key: val[-1] for key, val in hist.history.items()} for hist in results_ctr]\n",
        "    ).assign(\n",
        "    #r2_score    = lambda x: x.r2_score * 100,\n",
        "    #val_r2_score = lambda x: x.val_r2_score * 100\n",
        ")\n",
        "\n",
        "table.describe()[1:].to_csv(experiment_path + \"results/performance_train_overview.csv\", sep = \";\")\n",
        "table.round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p04R8pjSci_e"
      },
      "outputs": [],
      "source": [
        "# plot train result (MAE)\n",
        "# =======================\n",
        "\n",
        "y1 = np.array([hist.history[\"mae\"] for hist in results_ctr]).transpose()\n",
        "y2 = np.array([hist.history[\"val_mae\"] for hist in results_ctr]).transpose()\n",
        "\n",
        "plt.plot(y1, color = 'blue', alpha = .2)\n",
        "plt.plot(np.quantile(y1,.5, axis = 1), label = 'training', color = 'blue')\n",
        "plt.plot(y2, color = 'orange', alpha = .2)\n",
        "plt.plot(np.quantile(y2,.5, axis = 1), label = 'evaluation', color = 'orange')\n",
        "plt.ylim([None, 4000])\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Mean Absolute Error\")\n",
        "plt.suptitle('Federated Insurance', fontsize = 18)\n",
        "plt.title('centralized training performance')\n",
        "plt.legend()\n",
        "plt.savefig(experiment_path + 'results/training_performance_mae.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TZgYoAaci_e"
      },
      "outputs": [],
      "source": [
        "# plot train result (RSQ)\n",
        "# =======================\n",
        "\n",
        "y1 = np.array([hist.history[\"r2_score\"] for hist in results_ctr]).transpose()\n",
        "y2 = np.array([hist.history[\"val_r2_score\"] for hist in results_ctr]).transpose()\n",
        "\n",
        "plt.plot(y1, color = 'blue', alpha = .2)\n",
        "plt.plot(np.quantile(y1,.5, axis = 1), label = 'Training', color = 'blue')\n",
        "plt.plot(y2, color = 'orange', alpha = .2)\n",
        "plt.plot(np.quantile(y2,.5, axis = 1), label = 'Evaluation', color = 'orange')\n",
        "plt.ylim([0.5, 0.9])\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"R squared\")\n",
        "plt.suptitle('Federated Insurance', fontsize = 18)\n",
        "plt.title('centralized training performance')\n",
        "plt.legend()\n",
        "plt.savefig(experiment_path + 'results/training_performance_rsq.png')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC7ddIfHci_f"
      },
      "source": [
        "### CTR Test\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVAsd7BIci_f"
      },
      "outputs": [],
      "source": [
        "# compute test\n",
        "# ============\n",
        "\n",
        "results_test_ctr = []\n",
        "\n",
        "i = 0\n",
        "for train, test in tqdm.tqdm(list(evaluation.split(df, df.region))):\n",
        "    data_test = df.loc[test]\n",
        "\n",
        "    X_test, y_test = data_test[features], data_test[target]\n",
        "\n",
        "\n",
        "    model = results_ctr[i].model\n",
        "    i += 1\n",
        "    perf_test  = model.evaluate(X_test, y_test, verbose = 0)\n",
        "    perf_test = dict(zip(model.metrics_names, perf_test))\n",
        "    results_test_ctr.append(perf_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBblb5fRci_f"
      },
      "outputs": [],
      "source": [
        "# show test results\n",
        "# =================\n",
        "\n",
        "table2 = pd.DataFrame(results_test_ctr)\n",
        "table2 = table2.set_axis(['test_'+ col for col in table2.columns], axis = 1)\n",
        "\n",
        "\n",
        "table2.describe()[1:].to_csv(experiment_path + \"results/performance_test_overview.csv\", sep = \";\")\n",
        "\n",
        "table_all_ctr = pd.concat([table, table2], axis = 1)\n",
        "table_all_ctr.describe()[1:].to_csv(experiment_path + \"results/performance_overview.csv\", sep = \";\")\n",
        "table_all_ctr.to_csv(experiment_path + \"results/performance.csv\", sep = \";\")\n",
        "table_all_ctr.describe()[1:].transpose().round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qruNGxziYkJh"
      },
      "source": [
        "## Comparison\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uc249f5rYkJh"
      },
      "outputs": [],
      "source": [
        "# table of results\n",
        "# ================\n",
        "\n",
        "tab = pd.concat(\n",
        "    [\n",
        "    table_all_fed.loc[:,table_all_fed.columns.str.contains(\"mean|loss|mae|score\")].describe(percentiles = []).assign(type = \"federated\")[1:3].rename(\n",
        "        columns = {'mean_absolute_error': 'mae',\n",
        "\n",
        "                   'val_mean_absolute_error': 'val_mae',\n",
        "\n",
        "                   'test_mean_absolute_error': 'test_mae'\n",
        "                   }\n",
        "    ).transpose(),\n",
        "    table_all_ctr.describe(percentiles = []).assign(type = \"centralized\")[1:3].transpose()\n",
        "    ],\n",
        "    axis = 1)\n",
        "\n",
        "\n",
        "tab.loc[['type','loss', 'mae', 'mean_squared_error', 'r2_score',\n",
        "         'val_loss', 'val_mae', 'val_mean_squared_error', 'val_r2_score','test_loss',\n",
        "         'test_mae', 'test_mean_squared_error', 'test_r2_score'\n",
        "       ]]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}