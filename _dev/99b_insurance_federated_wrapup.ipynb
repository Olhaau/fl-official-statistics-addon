{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Insurance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open\n",
    "\n",
    "- [ ] RSquared for FL, but it is only available in tf-nightly and the installation broke the env\n",
    "- [ ] cache result\n",
    "- [x] centralized: does CSV Logger work with TFF? Or instead save the hist manually as csv\n",
    "- [x] logging/caching federated\n",
    "- [ ] document input and outputs in FLutils\n",
    "- [ ] move to and test colab"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLAB? False\n"
     ]
    }
   ],
   "source": [
    "# Setup colab if needed\n",
    "\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "\n",
    "print(\"COLAB? {}\".format(IN_COLAB))\n",
    "\n",
    "if IN_COLAB:\n",
    "    import os\n",
    "    \n",
    "    # rm repo from gdrive\n",
    "    if os.path.exists(\"fl-official-statistics-addon\"):\n",
    "      %rm -r fl-official-statistics-addon\n",
    "\n",
    "    # clone\n",
    "    !git clone https://github.com/Olhaau/fl-official-statistics-addon\n",
    "    %cd fl-official-statistics-addon\n",
    "\n",
    "    # pull (the currenct version of the repo)\n",
    "    !git pull\n",
    "\n",
    "    !pip install -q tensorflow-federated==0.56.0\n",
    "    # or maybe !pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/olihauke/.asdf/installs/python/miniconda3-latest/envs/env-tff/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Python 3.9.16\n"
     ]
    }
   ],
   "source": [
    "# python version\n",
    "!python --version\n",
    "# tested 3.9.* or 3.10.*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/olihauke/.asdf/installs/python/miniconda3-latest/envs/env-tff/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "tensorflow                    2.12.0\n",
      "tensorflow-addons             0.20.0\n",
      "tensorflow-compression        2.12.0\n",
      "tensorflow-datasets           4.9.2\n",
      "tensorflow-estimator          2.12.0\n",
      "tensorflow-federated          0.56.0\n",
      "tensorflow-io-gcs-filesystem  0.32.0\n",
      "tensorflow-metadata           1.13.1\n",
      "tensorflow-model-optimization 0.7.3\n",
      "tensorflow-privacy            0.8.8\n",
      "tensorflow-probability        0.15.0\n"
     ]
    }
   ],
   "source": [
    "# library versions\n",
    "!pip list | grep tensorflow\n",
    "# tensorflow                    2.12.0\n",
    "# tensorflow-federated          0.56.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress tf debug logging\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "#0 = all messages are logged (default behavior)\n",
    "#1 = INFO messages are not printed\n",
    "#2 = INFO and WARNING messages are not printed\n",
    "#3 = INFO, WARNING, and ERROR messages are not printed\n",
    "\n",
    "# S. https://stackoverflow.com/questions/35911252/disable-tensorflow-debugging-information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tqdm\n",
    "import tensorflow_federated as tff\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import RepeatedKFold, train_test_split\n",
    "\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "from FLutils import load_df, create_keras_model, model_fn, prep_fed_train, prep_fed_test, train_model,train_fed\n",
    "#import FLutils\n",
    "\n",
    "# logging path\n",
    "log_path = '../output/experiments' "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preperation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data from ../output/data/insurance-clean.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "      <th>region0</th>\n",
       "      <th>region1</th>\n",
       "      <th>region2</th>\n",
       "      <th>region3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.9240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.479150</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.5523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.217391</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.458434</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.4620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  sex       bmi  children  smoker     region     charges  region0  \\\n",
       "0  0.021739  0.0  0.321227       0.0     1.0  southwest  16884.9240      0.0   \n",
       "1  0.000000  1.0  0.479150       0.2     0.0  southeast   1725.5523      0.0   \n",
       "2  0.217391  1.0  0.458434       0.6     0.0  southeast   4449.4620      0.0   \n",
       "\n",
       "   region1  region2  region3  \n",
       "0      0.0      0.0      1.0  \n",
       "1      0.0      1.0      0.0  \n",
       "2      0.0      1.0      0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ingest data\n",
    "\n",
    "df_locs = [\n",
    "    '../output/data/insurance-clean.csv',\n",
    "    \"https://raw.githubusercontent.com/Olhaau/fl-official-statistics-addon/main/output/data/insurance-clean.csv\"\n",
    "]\n",
    "\n",
    "df = load_df(df_locs)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>charges</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region0</th>\n",
       "      <th>region1</th>\n",
       "      <th>region2</th>\n",
       "      <th>region3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16884.9240</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1725.5523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.479150</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4449.4620</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.458434</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      charges       age  sex       bmi  children  smoker  region0  region1  \\\n",
       "0  16884.9240  0.021739  0.0  0.321227       0.0     1.0      0.0      0.0   \n",
       "1   1725.5523  0.000000  1.0  0.479150       0.2     0.0      0.0      0.0   \n",
       "2   4449.4620  0.217391  1.0  0.458434       0.6     0.0      0.0      0.0   \n",
       "\n",
       "   region2  region3  \n",
       "0      0.0      1.0  \n",
       "1      1.0      0.0  \n",
       "2      1.0      0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select features and target (first column)\n",
    "# =========================================\n",
    "features = ['age', 'sex', 'bmi', 'children', 'smoker'\n",
    "            , 'region0', 'region1', 'region2', 'region3']#[:5]\n",
    "target = 'charges'\n",
    "\n",
    "df.loc[:, [target] + features].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clients shape: [(325, 10), (364, 10), (325, 10), (324, 10)]\n"
     ]
    }
   ],
   "source": [
    "# create client data\n",
    "# ==================\n",
    "\n",
    "clients = [\n",
    "    df.loc[df['region'] == x, [target] + features] for x in df['region'].unique()]\n",
    "\n",
    "# or randomly\n",
    "# clients = [df[[target] + features].sample(frac = 1./4, ignore_index = True) for _ in range(4)]\n",
    "\n",
    "print(\"clients shape: %s\" % [client.shape for client in clients])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation split\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of splits per client: [50, 50, 50, 50]\n"
     ]
    }
   ],
   "source": [
    "# create evaluation splits\n",
    "# ========================\n",
    "\n",
    "nreps, nfolds = 10, 5\n",
    "\n",
    "rsmp = RepeatedKFold(n_splits = nfolds, n_repeats = nreps, random_state = 42)\n",
    "client_splits = [list(rsmp.split(data)) for data in clients]\n",
    "\n",
    "\n",
    "print(\"number of splits per client: %s\" % [np.array(client, dtype = object).shape[0] for client in client_splits])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_evals  =   5 * nfolds # up to nfolds * nreps\n",
    "n_epochs = 100          # for centralized training\n",
    "n_rounds =  50          # federation rounds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated Learning\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = '03_federated'\n",
    "\n",
    "experiment_path = log_path + \"/\" + experiment_name + \"/\"\n",
    "if not os.path.exists(experiment_path + 'logs'): os.makedirs(experiment_path + 'logs')\n",
    "if not os.path.exists(experiment_path + 'models'): os.makedirs(experiment_path + 'models')\n",
    "if not os.path.exists(experiment_path + 'results'): os.makedirs(experiment_path + 'results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 40)                240       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                820       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,721\n",
      "Trainable params: 2,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential_1',\n",
       " 'layers': [{'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 5),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'input_2'}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_4',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 40,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_5',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 40,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_6',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 20,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_7',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 1,\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model architecture\n",
    "def keras_blueprint(compile = False, nfeatures = len(features[:5])):\n",
    "    if nfeatures == None: nfeatures = len(features)\n",
    "    \n",
    "    return create_keras_model(\n",
    "        nfeatures = nfeatures, \n",
    "        units = [40, 40, 20], \n",
    "        activations = ['relu'] * 3, \n",
    "        compile = compile)\n",
    "\n",
    "# Note: we do not compile the model yet. The loss, metrics, and optimizers are introduced later.\n",
    "# S. https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification#creating_a_model_with_keras\n",
    "\n",
    "# loss = mae -> overfitting?\n",
    "\n",
    "keras_blueprint().summary()\n",
    "\n",
    "keras_blueprint().get_config()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FED Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:22<08:55, 22.33s/it]"
     ]
    }
   ],
   "source": [
    "# compute train\n",
    "\n",
    "results_fed = []\n",
    "\n",
    "for eval_ind in tqdm.tqdm(range(n_evals)):\n",
    "\n",
    "    rep  = int(eval_ind / nfolds)\n",
    "    fold = int(eval_ind % nfolds)\n",
    "    id = \"r\" + str(rep) + \"f\" + str(fold)\n",
    "    #print('======= rep %s - fold %s  =======' % (rep, fold))\n",
    "\n",
    "\n",
    "    # fetch train, eval data and prep it\n",
    "    train_data_fed = []\n",
    "    eval_data_fed  = []\n",
    "\n",
    "    for client_ind in range(len(clients)):\n",
    "        indices_train = client_splits[client_ind][eval_ind][0]\n",
    "\n",
    "        data = clients[client_ind].iloc[indices_train]\n",
    "        train_data, eval_data = train_test_split(data, test_size = 0.1, random_state = 42)\n",
    "\n",
    "        train_data_fed.append(prep_fed_train(train_data[features[:5]], train_data[target])) \n",
    "        eval_data_fed.append( prep_fed_test( eval_data[features[:5]], eval_data[target]))\n",
    "        \n",
    "    # train\n",
    "    #with tf.device('/device:gpu:0'): # possibly needed for colab\n",
    "    result = train_fed(\n",
    "        model = model_fn(keras_creator = keras_blueprint),\n",
    "        train_data = train_data_fed,\n",
    "        eval_data  = eval_data_fed,\n",
    "        client_optimizer = lambda: tf.optimizers.Adam(learning_rate = .05),\n",
    "        server_optimizer = lambda: tf.optimizers.Adam(learning_rate = .05),\n",
    "        NUM_ROUNDS = n_rounds,\n",
    "        NUM_EPOCHS = 50,\n",
    "        BATCH_SIZE = 128,\n",
    "        SHUFFLE_BUFFER = 20,\n",
    "        PREFETCH_BUFFER = 5,\n",
    "        SEED = 42,\n",
    "        verbose = False\n",
    "    )\n",
    "\n",
    "    # caching\n",
    "    pd.DataFrame(result['history']).to_csv(experiment_path + \"logs/\" + id + '_log.csv', sep = \";\")\n",
    "\n",
    "    model = keras_blueprint()\n",
    "    model_weights = result['process'].get_model_weights(result['state'])\n",
    "    model_weights.assign_weights_to(model)\n",
    "    model.save_weights(experiment_path + \"models/\" + id + '_weights.h5')\n",
    "    # load with e.g. \n",
    "    # model = keras_blueprint(compile = True)\n",
    "    # model.load_weights(experiment_path + 'models/r0f0_weights.h5')\n",
    "    # model.weights\n",
    "\n",
    "    results_fed.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show final train result\n",
    "table = pd.DataFrame([result['history'][-1] for result in results_fed])\n",
    "table.describe().to_csv(experiment_path + \"results/performance_train_overview.csv\", sep = \";\")\n",
    "table.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train result\n",
    "\n",
    "y = np.array([[hist['mean_absolute_error'] for hist in res['history']] for res in results_fed]).transpose()\n",
    "yval = np.array([[hist['val_mean_absolute_error'] for hist in res['history']] for res in results_fed]).transpose()\n",
    "\n",
    "\n",
    "xran = range(1,y.shape[0] + 1)\n",
    "plt.plot(xran, y, color = 'blue', alpha = .2)\n",
    "plt.plot(xran, np.quantile(y,.5, axis = 1), label = 'training', color = 'blue')\n",
    "plt.plot(xran, yval, color = 'orange', alpha = .2)\n",
    "plt.plot(xran, np.quantile(yval,.5, axis = 1), label = 'evaluation', color = 'orange')\n",
    "plt.xlabel(\"Rounds\")\n",
    "plt.ylabel(\"Mean Absolute Error\")\n",
    "plt.suptitle('Federated Insurance', fontsize=18)\n",
    "plt.title('federated training performance')\n",
    "plt.legend()\n",
    "plt.savefig(experiment_path + 'results/training_performance_mae.png')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FED Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute test \n",
    "results_fed_test = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(results_fed))):\n",
    "\n",
    "    # fetch test data\n",
    "    clients_test = []\n",
    "    for client_ind in range(len(clients)):\n",
    "        indices_test = client_splits[client_ind][eval_ind][1]\n",
    "        clients_test.append(clients[client_ind].iloc[indices_test])\n",
    "\n",
    "    test_data = pd.concat(clients_test)\n",
    "    X_test = test_data[features[:5]]\n",
    "    y_test = test_data[target]\n",
    "\n",
    "    # calculate test performance\n",
    "    model = keras_blueprint(compile = True)\n",
    "    model_weights = results_fed[i]['process'].get_model_weights(results_fed[i]['state'])\n",
    "    model_weights.assign_weights_to(model)\n",
    "    \n",
    "    perf_test = model.evaluate(X_test, y_test, verbose = 0)\n",
    "    perf_test = dict(zip(model.metrics_names, perf_test))\n",
    "\n",
    "    results_fed_test.append(perf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show test results\n",
    "table2 = pd.DataFrame(results_fed_test)\n",
    "table2 = table2.set_axis(['test_'+ col for col in table2.columns], axis = 1)\n",
    "\n",
    "table2.describe()[1:].to_csv(experiment_path + \"results/performance_test_overview.csv\", sep = \";\")\n",
    "table_all = pd.concat([table, table2], axis = 1)\n",
    "table_all.describe()[1:].to_csv(experiment_path + \"results/performance_overview.csv\", sep = \";\")\n",
    "table_all.to_csv(experiment_path + \"results/performance.csv\", sep = \";\")\n",
    "\n",
    "table_all.describe()[1:].transpose().round(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centralized DNN\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 9 Features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = '02_central_new'\n",
    "\n",
    "experiment_path = log_path + \"/\" + experiment_name + \"/\"\n",
    "if not os.path.exists(experiment_path + 'logs'): os.makedirs(experiment_path + 'logs')\n",
    "if not os.path.exists(experiment_path + 'models'): os.makedirs(experiment_path + 'models')\n",
    "if not os.path.exists(experiment_path + 'results'): os.makedirs(experiment_path + 'results')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CTR Train\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# compute train\n",
    "\n",
    "results_ctr = []\n",
    "\n",
    "for i in range(n_evals):\n",
    "\n",
    "    train_indices = [split[1][0] for split in client_splits]\n",
    "    #test_indices = [split[1][1] for split in client_splits]\n",
    "\n",
    "    rep  = int(i / nfolds)\n",
    "    fold = int(i % nfolds)\n",
    "    id = \"r\" + str(rep) + \"f\" + str(fold)\n",
    "    print('======= rep %s - fold %s  =======' % (rep, fold))\n",
    "\n",
    "    data_train = pd.concat([clients[i].iloc[train_indices[i]] for i in range(len(clients))])\n",
    "    X_train = data_train[features[:9]] # include regions\n",
    "    y_train = data_train[target]\n",
    "\n",
    "    model = keras_blueprint(nfeatures = 9, compile = True)\n",
    "    \n",
    "    hist = train_model(\n",
    "        model, X_train, y_train,\n",
    "        epochs = n_epochs, \n",
    "        output_msr = \"r2_score\",\n",
    "        callbacks = [CSVLogger(experiment_path + \"logs/\" + id + '_log.csv'  , separator =\";\")],\n",
    "        seed = 42\n",
    "    )\n",
    "    model.save_weights(experiment_path + \"models/\" + id + '_weights.h5')\n",
    "\n",
    "    results_ctr.append(hist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show train results\n",
    "table = pd.DataFrame(\n",
    "    [{key: val[-1] for key, val in hist.history.items()} for hist in results_ctr]\n",
    "    ).assign(\n",
    "    r2_score    = lambda x: x.r2_score * 100,\n",
    "    val_r2_score = lambda x: x.val_r2_score * 100\n",
    ")\n",
    "\n",
    "table.describe()[1:].to_csv(experiment_path + \"results/performance_train_overview.csv\", sep = \";\")\n",
    "table.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train result\n",
    "y1 = np.array([hist.history[\"mae\"] for hist in results_ctr]).transpose()\n",
    "y2 = np.array([hist.history[\"val_mae\"] for hist in results_ctr]).transpose()\n",
    "\n",
    "plt.plot(y1, color = 'blue', alpha = .2)\n",
    "plt.plot(np.quantile(y1,.5, axis = 1), label = 'training', color = 'blue')\n",
    "plt.plot(y2, color = 'orange', alpha = .2)\n",
    "plt.plot(np.quantile(y2,.5, axis = 1), label = 'evaluation', color = 'orange')\n",
    "plt.ylim([None, 4000])\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Mean Absolute Error\")\n",
    "plt.suptitle('Federated Insurance', fontsize = 18)\n",
    "plt.title('centralized training performance')\n",
    "plt.legend()\n",
    "plt.savefig(experiment_path + 'results/training_performance_mae.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train result\n",
    "y1 = np.array([hist.history[\"r2_score\"] for hist in results_ctr]).transpose()\n",
    "y2 = np.array([hist.history[\"val_r2_score\"] for hist in results_ctr]).transpose()\n",
    "\n",
    "plt.plot(y1, color = 'blue', alpha = .2)\n",
    "plt.plot(np.quantile(y1,.5, axis = 1), label = 'Training', color = 'blue')\n",
    "plt.plot(y2, color = 'orange', alpha = .2)\n",
    "plt.plot(np.quantile(y2,.5, axis = 1), label = 'Evaluation', color = 'orange')\n",
    "plt.ylim([0.5, 0.9])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"R squared\")\n",
    "plt.suptitle('Federated Insurance', fontsize = 18)\n",
    "plt.title('centralized training performance')\n",
    "plt.legend()\n",
    "plt.savefig(experiment_path + 'results/training_performance_rsq.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CTR Test\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute test\n",
    "results_test_ctr = []\n",
    "\n",
    "for i in tqdm.tqdm(range(\n",
    "    3\n",
    "    #nfolds * nreps - 40\n",
    "    )):\n",
    "    #train_indices = [split[1][0] for split in client_splits]\n",
    "    test_indices = [split[1][1] for split in client_splits]\n",
    "\n",
    "    data_test = pd.concat([clients[i].iloc[test_indices[i]] for i in range(len(clients))])\n",
    "    X_test = data_test[features[:9]]\n",
    "    y_test = data_test[target]\n",
    "\n",
    "    model = results_ctr[i].model\n",
    "    perf_test  = model.evaluate(X_test, y_test, verbose = 0)\n",
    "    perf_test = dict(zip(model.metrics_names, perf_test))\n",
    "    results_test_ctr.append(perf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show test results\n",
    "table2 = pd.DataFrame(results_test_ctr)\n",
    "table2 = table2.set_axis(['test_'+ col for col in table2.columns], axis = 1)\n",
    "\n",
    "\n",
    "table2.describe()[1:].to_csv(experiment_path + \"results/performance_test_overview.csv\", sep = \";\")\n",
    "\n",
    "table_all = pd.concat([table, table2], axis = 1)\n",
    "table_all.describe()[1:].to_csv(experiment_path + \"results/performance_overview.csv\", sep = \";\")\n",
    "table_all.to_csv(experiment_path + \"results/performance.csv\", sep = \";\")\n",
    "table_all.describe()[1:].transpose().round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
