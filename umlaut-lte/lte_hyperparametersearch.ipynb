{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-20 15:19:47.478161: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-20 15:19:47.478201: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-20 15:19:47.509877: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-20 15:19:49.554182: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-20 15:19:49.554299: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-20 15:19:49.554313: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, ShuffleSplit\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from tensorflow_addons.metrics import RSquare\n",
    "import keras_tuner\n",
    "\n",
    "from umlaut_lte import write_result, get_data_csv, plot_loss\n",
    "\n",
    "result_file = './results.txt'\n",
    "input_data_file = 'data/lte.csv'\n",
    "dnn_loss_fig_path = './dnn-loss-fig.png'\n",
    "\n",
    "# Values dependent on the data availability and time frame\n",
    "threshold_min_days_per_user = 20\n",
    "test_split_size = 0.3  # relative value\n",
    "validation_split_size = 0.3  # relative value\n",
    "dnn_batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_random_forest(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Performs a hyperparameter search for a random forest on the given data. The results are written\n",
    "    to the result.txt file.\n",
    "\n",
    "    :param X_train: The data to train\n",
    "    :type X_train: numpy.Array\n",
    "    :param X_test: The data to test the model\n",
    "    :type X_test: numpy.Array\n",
    "    :param y_train: The labels to train the model\n",
    "    :type y_train: numpy.Array\n",
    "    :param y_test: The labels for the given test data\n",
    "    :type y_test: numpy.Array\n",
    "    \"\"\"\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [4, 5, 6, 8, 10, 12, 15, 20, 25, 30, 35, 40, 50, 60, 80, 100, 120]\n",
    "    max_features = [0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_depth': max_depth,\n",
    "                   'max_features': max_features,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "    # Random search of parameters, using 3 fold cross validation,\n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    rf_random = RandomizedSearchCV(\n",
    "        estimator=rf,\n",
    "        param_distributions=random_grid,\n",
    "        n_iter=1200,\n",
    "        cv=3,\n",
    "        verbose=1,\n",
    "        random_state=0,\n",
    "        n_jobs=-1  # use all available CPU cores\n",
    "    )\n",
    "    rf_random.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    write_result(f'BEST PARAMS: {rf_random.best_params_}')\n",
    "\n",
    "    # create classifier with found parameters\n",
    "    clf_rf = RandomForestRegressor(**rf_random.best_params_)\n",
    "\n",
    "    # VALIDATE\n",
    "\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=validation_split_size, random_state=0)\n",
    "    scores = cross_val_score(clf_rf, X_train, y_train.values.ravel(), cv=cv)\n",
    "    write_result(\"RANDOM FOREST cross validation: %0.5f mean R^2 with a standard deviation of %0.5f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "    clf_rf.fit(X_train, y_train.values.ravel())\n",
    "    test_score = clf_rf.score(X_test, y_test.values.ravel())\n",
    "\n",
    "    write_result(f'RANDOM FOREST test score: {test_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_dnn_model(hp):\n",
    "    \"\"\"Builds the DNN model and compiles it.\n",
    "\n",
    "    :param hp: The HyperParameters to use\n",
    "    :type hp: keras_tuner.HyperParameters\n",
    "    :return: Compiled keras model\n",
    "    :rtype: keras.Model\n",
    "    \"\"\"\n",
    "    model = keras.Sequential()\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            # Define the hyperparameter.\n",
    "            units=hp.Int(\"units_0\", min_value=8, max_value=80, step=8),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "    )\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(\n",
    "            rate=hp.Float(\"dropout_rate\", min_value=0.1, max_value=0.3, step=0.05)\n",
    "        ))\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            # Define the hyperparameter.\n",
    "            units=hp.Int(\"units_1\", min_value=2, max_value=16, step=4),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "    )\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(\n",
    "        optimizer=\"sgd\",\n",
    "        loss=\"mae\",\n",
    "        metrics=[\"mae\", 'mean_squared_error', RSquare()],\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_dnn(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Performs a hyperparameter search for a DNN on the given data. The results are written\n",
    "    to the result.txt file.\n",
    "\n",
    "    :param X_train: The data to train\n",
    "    :type X_train: numpy.Array\n",
    "    :param X_test: The data to test the model\n",
    "    :type X_test: numpy.Array\n",
    "    :param y_train: The labels to train the model\n",
    "    :type y_train: numpy.Array\n",
    "    :param y_test: The labels for the given test data\n",
    "    :type y_test: numpy.Array\n",
    "    \"\"\"\n",
    "    build_dnn_model(keras_tuner.HyperParameters())\n",
    "\n",
    "    tuner = keras_tuner.RandomSearch(\n",
    "        hypermodel=build_dnn_model,\n",
    "        objective=\"val_mae\",\n",
    "        max_trials=100,\n",
    "        executions_per_trial=2,\n",
    "        overwrite=True,\n",
    "        directory=None,\n",
    "        project_name=\"insurance-dnn-tuner\",\n",
    "    )\n",
    "\n",
    "    tuner.search(X_train, y_train, epochs=100, validation_split=validation_split_size)\n",
    "    best_hps = tuner.get_best_hyperparameters(5)\n",
    "    best_model = build_dnn_model(best_hps[0])\n",
    "    best_model.build(input_shape=(None,X_train.shape[1]))\n",
    "\n",
    "    write_result('BEST DNN model architecture:')\n",
    "    best_model.summary(print_fn=write_result)\n",
    "\n",
    "    history = best_model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=dnn_batch_size,\n",
    "        shuffle=True,\n",
    "        validation_split=validation_split_size,\n",
    "        epochs=100)\n",
    "    plot_loss(history)\n",
    "    scores = best_model.evaluate(X_test, y_test)\n",
    "    write_result('Testing trained DNN (mae_loss, mae, mse, r_square):')\n",
    "    write_result(str(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_lin_reg(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Performs a hyperparameter search for a linear regression model on the given data. The results are\n",
    "    written to the result.txt file.\n",
    "\n",
    "    :param X_train: The data to train\n",
    "    :type X_train: numpy.Array\n",
    "    :param X_test: The data to test the model\n",
    "    :type X_test: numpy.Array\n",
    "    :param y_train: The labels to train the model\n",
    "    :type y_train: numpy.Array\n",
    "    :param y_test: The labels for the given test data\n",
    "    :type y_test: numpy.Array\n",
    "    \"\"\"\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=validation_split_size, random_state=0)\n",
    "    clf_lr = LinearRegression()\n",
    "    scores = cross_val_score(clf_lr, X_train, y_train.values.ravel(), cv=cv)\n",
    "    write_result(\"LINEAR REGRESSION cross validation: %0.5f mean R^2 with a standard deviation of %0.5f\" % (scores.mean(), scores.std()))\n",
    "    clf_lr.fit(X_train, y_train.values.ravel())\n",
    "    test_score = clf_lr.score(X_test, y_test.values.ravel())\n",
    "    write_result(f'LINEAR REGRESSION test score: {test_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "running with threshold 0,data point threshold 10,and test split 0.2...\n",
      "target variable: radius_activity_user\n",
      "Ignoring velocity? True\n",
      "before filtering data: 864 rows in data set.\n",
      "after filtering data: 864 rows in data set.\n"
     ]
    }
   ],
   "source": [
    "# All the functions are run here because it has been used as a script on another machine\n",
    "# The results found here are not comparable to the results found by Umlaut, as it runs\n",
    "# on a very small amount of dummy data. The settings found by Umlaut are used in\n",
    "# lte_federated.ipynb\n",
    "write_result('Loading data...')\n",
    "X_train, X_test, y_train, y_test = get_data_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting RANDOM FOREST hyperparameter search...\n",
      "Fitting 3 folds for each of 1200 candidates, totalling 3600 fits\n",
      "BEST PARAMS: {'n_estimators': 400, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 0.9, 'max_depth': 80, 'bootstrap': True}\n",
      "RANDOM FOREST cross validation: 0.99465 mean R^2 with a standard deviation of 0.00087\n",
      "RANDOM FOREST test score: 0.9956233164232386\n",
      "DONE (RANDOM FOREST)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "write_result('\\nStarting RANDOM FOREST hyperparameter search...')\n",
    "run_random_forest(X_train, X_test, y_train, y_test)\n",
    "write_result('DONE (RANDOM FOREST)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 22 Complete [00h 00m 17s]\n",
      "val_mae: 5677.7119140625\n",
      "\n",
      "Best val_mae So Far: 5475.080810546875\n",
      "Total elapsed time: 00h 06m 22s\n",
      "\n",
      "Search: Running Trial #23\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "56                |56                |units_0\n",
      "False             |False             |dropout\n",
      "2                 |10                |units_1\n",
      "0.2               |0.2               |dropout_rate\n",
      "\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 23ms/step - loss: 8749.0566 - mae: 8749.0566 - mean_squared_error: 521770720.0000 - r_square: -0.1719 - val_loss: 7162.8130 - val_mae: 7162.8130 - val_mean_squared_error: 387165632.0000 - val_r_square: -0.1527\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 8744.1670 - mae: 8744.1670 - mean_squared_error: 521585440.0000 - r_square: -0.1715 - val_loss: 7143.9697 - val_mae: 7143.9697 - val_mean_squared_error: 386485312.0000 - val_r_square: -0.1507\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 8555.1260 - mae: 8555.1260 - mean_squared_error: 511324480.0000 - r_square: -0.1485 - val_loss: 6693.3403 - val_mae: 6693.3403 - val_mean_squared_error: 364170112.0000 - val_r_square: -0.0843\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 8279.3262 - mae: 8279.3262 - mean_squared_error: 491323392.0000 - r_square: -0.1035 - val_loss: 6610.7061 - val_mae: 6610.7061 - val_mean_squared_error: 360435424.0000 - val_r_square: -0.0731\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 8205.7393 - mae: 8205.7393 - mean_squared_error: 476462464.0000 - r_square: -0.0702 - val_loss: 6583.7583 - val_mae: 6583.7583 - val_mean_squared_error: 368924832.0000 - val_r_square: -0.0984\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 8164.2705 - mae: 8164.2705 - mean_squared_error: 487788832.0000 - r_square: -0.0956 - val_loss: 6323.4375 - val_mae: 6323.4375 - val_mean_squared_error: 300908352.0000 - val_r_square: 0.1041\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8065.7959 - mae: 8065.7959 - mean_squared_error: 464661408.0000 - r_square: -0.0437 - val_loss: 6230.8315 - val_mae: 6230.8315 - val_mean_squared_error: 345754816.0000 - val_r_square: -0.0294\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7868.3550 - mae: 7868.3550 - mean_squared_error: 473677120.0000 - r_square: -0.0639 - val_loss: 6586.9634 - val_mae: 6586.9634 - val_mean_squared_error: 371075136.0000 - val_r_square: -0.1048\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7822.4736 - mae: 7822.4736 - mean_squared_error: 466998752.0000 - r_square: -0.0489 - val_loss: 6817.3882 - val_mae: 6817.3882 - val_mean_squared_error: 371658752.0000 - val_r_square: -0.1066\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7983.7041 - mae: 7983.7041 - mean_squared_error: 470420576.0000 - r_square: -0.0566 - val_loss: 6975.9810 - val_mae: 6975.9810 - val_mean_squared_error: 380866688.0000 - val_r_square: -0.1340\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8087.9731 - mae: 8087.9731 - mean_squared_error: 486527008.0000 - r_square: -0.0928 - val_loss: 6474.9644 - val_mae: 6474.9644 - val_mean_squared_error: 328880960.0000 - val_r_square: 0.0208\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 7889.5874 - mae: 7889.5874 - mean_squared_error: 466680576.0000 - r_square: -0.0482 - val_loss: 6120.8213 - val_mae: 6120.8213 - val_mean_squared_error: 318466752.0000 - val_r_square: 0.0518\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7796.8408 - mae: 7796.8408 - mean_squared_error: 449061696.0000 - r_square: -0.0086 - val_loss: 6222.2534 - val_mae: 6222.2534 - val_mean_squared_error: 358231904.0000 - val_r_square: -0.0666\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7916.0767 - mae: 7916.0767 - mean_squared_error: 471026752.0000 - r_square: -0.0580 - val_loss: 7362.9473 - val_mae: 7362.9473 - val_mean_squared_error: 285329536.0000 - val_r_square: 0.1505\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 8054.6777 - mae: 8054.6777 - mean_squared_error: 465950784.0000 - r_square: -0.0466 - val_loss: 6075.7090 - val_mae: 6075.7090 - val_mean_squared_error: 329716000.0000 - val_r_square: 0.0183\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7675.2441 - mae: 7675.2441 - mean_squared_error: 462813760.0000 - r_square: -0.0395 - val_loss: 6309.1479 - val_mae: 6309.1479 - val_mean_squared_error: 351080000.0000 - val_r_square: -0.0453\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7726.6943 - mae: 7726.6943 - mean_squared_error: 477060032.0000 - r_square: -0.0715 - val_loss: 5958.2183 - val_mae: 5958.2183 - val_mean_squared_error: 319854112.0000 - val_r_square: 0.0477\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7825.5664 - mae: 7825.5664 - mean_squared_error: 466267872.0000 - r_square: -0.0473 - val_loss: 6296.2627 - val_mae: 6296.2627 - val_mean_squared_error: 288128480.0000 - val_r_square: 0.1421\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7979.4048 - mae: 7979.4048 - mean_squared_error: 461406080.0000 - r_square: -0.0363 - val_loss: 6487.1611 - val_mae: 6487.1611 - val_mean_squared_error: 282228064.0000 - val_r_square: 0.1597\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7919.5513 - mae: 7919.5513 - mean_squared_error: 473477824.0000 - r_square: -0.0635 - val_loss: 6303.3486 - val_mae: 6303.3486 - val_mean_squared_error: 286011200.0000 - val_r_square: 0.1484\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7740.0522 - mae: 7740.0522 - mean_squared_error: 461738368.0000 - r_square: -0.0371 - val_loss: 8465.6924 - val_mae: 8465.6924 - val_mean_squared_error: 333552288.0000 - val_r_square: 0.0069\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7938.7056 - mae: 7938.7056 - mean_squared_error: 451009728.0000 - r_square: -0.0130 - val_loss: 6256.3364 - val_mae: 6256.3364 - val_mean_squared_error: 357364160.0000 - val_r_square: -0.0640\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7686.4800 - mae: 7686.4800 - mean_squared_error: 467355424.0000 - r_square: -0.0497 - val_loss: 5878.8091 - val_mae: 5878.8091 - val_mean_squared_error: 328105536.0000 - val_r_square: 0.0231\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7705.8237 - mae: 7705.8237 - mean_squared_error: 461623680.0000 - r_square: -0.0368 - val_loss: 6419.8091 - val_mae: 6419.8091 - val_mean_squared_error: 368612160.0000 - val_r_square: -0.0975\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7725.2666 - mae: 7725.2666 - mean_squared_error: 455490240.0000 - r_square: -0.0231 - val_loss: 5935.7290 - val_mae: 5935.7290 - val_mean_squared_error: 330498848.0000 - val_r_square: 0.0160\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7803.8286 - mae: 7803.8286 - mean_squared_error: 464931136.0000 - r_square: -0.0443 - val_loss: 7019.3804 - val_mae: 7019.3804 - val_mean_squared_error: 385716352.0000 - val_r_square: -0.1484\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8221.1221 - mae: 8221.1221 - mean_squared_error: 506958176.0000 - r_square: -0.1387 - val_loss: 6281.6953 - val_mae: 6281.6953 - val_mean_squared_error: 367829984.0000 - val_r_square: -0.0952\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7804.9761 - mae: 7804.9761 - mean_squared_error: 490651968.0000 - r_square: -0.1020 - val_loss: 8432.5273 - val_mae: 8432.5273 - val_mean_squared_error: 324307616.0000 - val_r_square: 0.0344\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7897.6704 - mae: 7897.6704 - mean_squared_error: 466844320.0000 - r_square: -0.0486 - val_loss: 16967.6953 - val_mae: 16967.6953 - val_mean_squared_error: 1156986112.0000 - val_r_square: -2.4448\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8027.1167 - mae: 8027.1167 - mean_squared_error: 484249856.0000 - r_square: -0.0877 - val_loss: 6086.6494 - val_mae: 6086.6494 - val_mean_squared_error: 341341312.0000 - val_r_square: -0.0163\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7737.6387 - mae: 7737.6387 - mean_squared_error: 479596320.0000 - r_square: -0.0772 - val_loss: 6164.6113 - val_mae: 6164.6113 - val_mean_squared_error: 351018336.0000 - val_r_square: -0.0451\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7727.8481 - mae: 7727.8481 - mean_squared_error: 477191840.0000 - r_square: -0.0718 - val_loss: 6896.4292 - val_mae: 6896.4292 - val_mean_squared_error: 384966368.0000 - val_r_square: -0.1462\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8076.1743 - mae: 8076.1743 - mean_squared_error: 504780320.0000 - r_square: -0.1338 - val_loss: 6243.3237 - val_mae: 6243.3237 - val_mean_squared_error: 368729088.0000 - val_r_square: -0.0978\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7809.5317 - mae: 7809.5317 - mean_squared_error: 487676416.0000 - r_square: -0.0953 - val_loss: 6021.5747 - val_mae: 6021.5747 - val_mean_squared_error: 358871520.0000 - val_r_square: -0.0685\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7712.4126 - mae: 7712.4126 - mean_squared_error: 483305760.0000 - r_square: -0.0855 - val_loss: 6860.8638 - val_mae: 6860.8638 - val_mean_squared_error: 285226816.0000 - val_r_square: 0.1508\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7830.9849 - mae: 7830.9849 - mean_squared_error: 454566560.0000 - r_square: -0.0210 - val_loss: 6575.4653 - val_mae: 6575.4653 - val_mean_squared_error: 382625632.0000 - val_r_square: -0.1392\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8016.8525 - mae: 8016.8525 - mean_squared_error: 509845056.0000 - r_square: -0.1451 - val_loss: 6629.9893 - val_mae: 6629.9893 - val_mean_squared_error: 291024768.0000 - val_r_square: 0.1335\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7917.1084 - mae: 7917.1084 - mean_squared_error: 477881184.0000 - r_square: -0.0733 - val_loss: 6230.5513 - val_mae: 6230.5513 - val_mean_squared_error: 355542816.0000 - val_r_square: -0.0586\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7768.6626 - mae: 7768.6626 - mean_squared_error: 484007520.0000 - r_square: -0.0871 - val_loss: 6044.8857 - val_mae: 6044.8857 - val_mean_squared_error: 346820064.0000 - val_r_square: -0.0326\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7707.7480 - mae: 7707.7480 - mean_squared_error: 483183104.0000 - r_square: -0.0853 - val_loss: 6055.6484 - val_mae: 6055.6484 - val_mean_squared_error: 360877440.0000 - val_r_square: -0.0745\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7760.7896 - mae: 7760.7896 - mean_squared_error: 487958592.0000 - r_square: -0.0960 - val_loss: 6739.4873 - val_mae: 6739.4873 - val_mean_squared_error: 383830240.0000 - val_r_square: -0.1428\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8136.4385 - mae: 8136.4385 - mean_squared_error: 515301824.0000 - r_square: -0.1574 - val_loss: 6494.6753 - val_mae: 6494.6753 - val_mean_squared_error: 382875648.0000 - val_r_square: -0.1400\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7961.6104 - mae: 7961.6104 - mean_squared_error: 501833536.0000 - r_square: -0.1271 - val_loss: 6235.2769 - val_mae: 6235.2769 - val_mean_squared_error: 367869600.0000 - val_r_square: -0.0953\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7739.1074 - mae: 7739.1074 - mean_squared_error: 489521632.0000 - r_square: -0.0995 - val_loss: 6073.3076 - val_mae: 6073.3076 - val_mean_squared_error: 333514240.0000 - val_r_square: 0.0070\n",
      "Epoch 45/100\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 8619.1641 - mae: 8619.1641 - mean_squared_error: 557828288.0000 - r_square: -0.0639"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m write_result(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStarting DNN hyperparameter search...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mrun_dnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m write_result(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDONE (DNN)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mrun_dnn\u001b[0;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m     14\u001b[0m build_dnn_model(keras_tuner\u001b[38;5;241m.\u001b[39mHyperParameters())\n\u001b[1;32m     16\u001b[0m tuner \u001b[38;5;241m=\u001b[39m keras_tuner\u001b[38;5;241m.\u001b[39mRandomSearch(\n\u001b[1;32m     17\u001b[0m     hypermodel\u001b[38;5;241m=\u001b[39mbuild_dnn_model,\n\u001b[1;32m     18\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_mae\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minsurance-dnn-tuner\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m )\n\u001b[0;32m---> 26\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m best_hps \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_hyperparameters(\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     28\u001b[0m best_model \u001b[38;5;241m=\u001b[39m build_dnn_model(best_hps[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py:183\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 183\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:295\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    294\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 295\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:222\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    221\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 222\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m tuner_utils\u001b[38;5;241m.\u001b[39mvalidate_trial_results(\n\u001b[1;32m    224\u001b[0m     results, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperModel.fit()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m )\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras_tuner/engine/hypermodel.py:140\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1555\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m   1552\u001b[0m     data_handler\u001b[38;5;241m.\u001b[39m_initial_step \u001b[38;5;241m=\u001b[39m data_handler\u001b[38;5;241m.\u001b[39m_initial_step \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1553\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_load_initial_step_from_ckpt()\n\u001b[1;32m   1554\u001b[0m     )\n\u001b[0;32m-> 1555\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[1;32m   1556\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m             epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m             _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m         ):\n\u001b[1;32m   1563\u001b[0m             callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/data_adapter.py:1374\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[1;32m   1373\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1374\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m   1375\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1376\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m original_spe\n\u001b[1;32m   1379\u001b[0m )\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:637\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    636\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    638\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    639\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:725\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;124;03m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m \n\u001b[1;32m    718\u001b[0m \u001b[38;5;124;03mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;124;03m  The value of the variable.\u001b[39;00m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 725\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_variable_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39midentity(value)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:704\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[0;34m(self, no_copy)\u001b[0m\n\u001b[1;32m    702\u001b[0m       result \u001b[38;5;241m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mread_and_set_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mno_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    707\u001b[0m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[1;32m    708\u001b[0m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[1;32m    709\u001b[0m   tape\u001b[38;5;241m.\u001b[39mrecord_operation(\n\u001b[1;32m    710\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle],\n\u001b[1;32m    711\u001b[0m       backward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[1;32m    712\u001b[0m       forward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:694\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[0;34m(no_copy)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_copy \u001b[38;5;129;01mand\u001b[39;00m forward_compat\u001b[38;5;241m.\u001b[39mforward_compatible(\u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m    693\u001b[0m   gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mdisable_copy_on_read(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m--> 694\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_resource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_variable_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, result)\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py:525\u001b[0m, in \u001b[0;36mread_variable_op\u001b[0;34m(resource, dtype, name)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m    524\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 525\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReadVariableOp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    528\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "write_result('Starting DNN hyperparameter search...')\n",
    "run_dnn(X_train, X_test, y_train, y_test)\n",
    "write_result('DONE (DNN)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_result('Starting LINEAR REGRESSION...')\n",
    "run_lin_reg(X_train, X_test, y_train, y_test)\n",
    "write_result('DONE (LINEAR REGRESSION)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
